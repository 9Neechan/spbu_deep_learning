{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Iterable, Tuple\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No CUDA device found\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|startoftext|>Друзья мои, чтобы соответствовать вам, я готов сделать над собой усилие и стать лучше. Но тогда и вы станьте немного хуже!\\n\\n<|startoftext|>- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н...\\n\\n<|startoftext|>- А вот скажи честно, ты во сне храпишь?- Понятие не имею, вроде, нет. От со'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r\"anek_djvu.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "text[118:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_data(text):\n",
    "    return text.replace(\"\\n\\n\", \"\").split(\"<|startoftext|>\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_text = cut_data(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Друзья мои, чтобы соответствовать вам, я готов сделать над собой усилие и стать лучше. Но тогда и вы станьте немного хуже!',\n",
       " '- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н...',\n",
       " '- А вот скажи честно, ты во сне храпишь?- Понятие не имею, вроде, нет. От собственного храпа по крайней мере еще ни разу не просыпался.- Ну, так у жены спроси.- А жена и подавно не знает. У нее странная привычка после замужества возникла: как спать ложится - беруши вставляет.',\n",
       " 'Поссорилась с мужем. Пока он спал, я мысленно развелась с ним, поделила имущество, переехала, поняла, что жить без него не могу, дала последний шанс, вернулась. В итоге, ложусь спать уже счастливой женщиной.',\n",
       " 'Если тебя посещают мысли о смерти - это еще полбеды. Беда - это когда смерть посещают мысли о тебе...']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_text[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1\n",
    "\n",
    "Обучите RNN/LSTM на данных из классной работы, используя другой токенайзер. Опишите его и свой выбор. Покажите разницу в генерации моделей, обученных с разными токенайзерами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенайзер из библиотеки **sentencepiece**: \n",
    "- работает с неразмеченными данными\n",
    "- разбивает его на подсловные юниты, что позволяет лучше справляться с редкими словами и морфологически сложными языками\n",
    "- поддерживает несколько методов токенизации, включая BPE (Byte Pair Encoding)\n",
    "\n",
    "BPE:\n",
    "- На каждом шаге алгоритм находит наиболее часто встречающуюся пару соседних символов или последовательностей символов и объединяет их в новый символ или токен.\n",
    "- Обновление: Этот процесс повторяется, пока не будет достигнуто заданное количество токенов или не останется частых пар для объединения.\n",
    "\n",
    "Преимущества:\n",
    "- Обработка редких слов: BPE позволяет разбивать редкие слова на более частые подсловные юниты, что улучшает обобщающую способность моделей.\n",
    "- Гибкость: Позволяет контролировать размер словаря, что важно для управления ресурсами и производительностью моделей.\n",
    "- Языконезависимость: Может применяться к любому языку, так как не зависит от предварительной сегментации на слова.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['▁', '|', 'startoftext', '|>', 'Д', 'ру', 'з', 'ья', '▁мо', 'и', ',', '▁чтобы', '▁со', 'о', 'т', 'вет', 'ство', 'вать', '▁вам', ',', '▁я', '▁го', 'тов', '▁сдела', 'ть', '▁на', 'д', '▁со', 'бой', '▁у', 'си', 'ли', 'е', '▁и', '▁ста', 'ть', '▁луч', 'ше', '.', '▁Но', '▁то', 'гда', '▁и', '▁вы', '▁ста', 'нь', 'те', '▁не', 'м', 'ного', '▁х', 'уж', 'е', '!', '▁<|', 'startoftext', '|>-', '▁Л', 'ю', 'ся', ',', '▁ты', '▁все', '▁еще', '▁х', 'ра', 'ни', 'шь', '▁мо', 'й', '▁по', 'да', 'ро', 'к', '?-', '▁Да', '.-', '▁Я', '▁дума', 'л', ',', '▁ты', '▁вы', 'ки', 'ну', 'ла', '▁все', ',', '▁что', '▁со', '▁м', 'ной', '▁с', 'в', 'я', 'за', 'но', '.-', '▁П', 'лю', 'ше', 'вый', '▁ми', 'шка', '▁не', '▁ви', 'но', 'ва', 'т', ',', '▁что', '▁ты', '▁е', 'б', 'л', '@', 'н', '...', '▁<|', 'startoftext', '|>-', '▁А', '▁вот', '▁ска', 'жи', '▁че', 'ст', 'но', ',', '▁ты', '▁во', '▁с', 'не', '▁х', 'ра', 'пи', 'шь', '?-', '▁По', 'ня', 'ти', 'е', '▁не', '▁и', 'ме', 'ю', ',', '▁в', 'ро', 'де', ',', '▁нет', '.', '▁О', 'т', '▁со']\n",
      "Detokenized text: |startoftext|>Друзья мои, чтобы соответствовать вам, я готов сделать над собой усилие и стать лучше. Но тогда и вы станьте немного хуже! <|startoftext|>- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н... <|startoftext|>- А вот скажи честно, ты во сне храпишь?- Понятие не имею, вроде, нет. От со\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# Обучаем токенайзер\n",
    "spm.SentencePieceTrainer.train(input='anek_djvu.txt', model_prefix='m', vocab_size=700, model_type='bpe')\n",
    "\n",
    "# Загружаем обученный токенайзер\n",
    "sp = spm.SentencePieceProcessor();\n",
    "sp.load('m.model') # загружаем модель в файл\n",
    "\n",
    "# Токенизация текста\n",
    "tokens = sp.encode_as_pieces(text[118:500])\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Детокенизация\n",
    "detokenized_text = sp.decode_pieces(tokens)\n",
    "print(\"Detokenized text:\", detokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPTokenizer:\n",
    "    def __init__(self, model_path: str):\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.load(model_path)\n",
    "        self.int2voc = {i: self.sp.id_to_piece(i).replace('▁', ' ') for i in range(self.sp.get_piece_size())}\n",
    "        self.voc2int = {v: k for k, v in self.int2voc.items()}\n",
    "        self._add_special(\"<pad>\")\n",
    "        self._add_special('<bos>')\n",
    "        self._add_special('<eos>')\n",
    "        self._add_special('<unk>') \n",
    "    \n",
    "    def _add_special(self, symbol) -> None:\n",
    "        idx = len(self.voc2int)\n",
    "        if symbol not in self.voc2int:\n",
    "            self.voc2int[symbol] = idx\n",
    "            self.int2voc[idx] = symbol\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.voc2int)\n",
    "        \n",
    "    def encode(self, chars):\n",
    "        #return torch.tensor(self.sp.encode_as_ids(text))\n",
    "        chars = ['<bos>'] + list(chars)\n",
    "        return torch.tensor(self.str_to_idx(chars))\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        #return self.sp.decode_ids(ids.tolist())\n",
    "        chars = self.idx_to_str(ids.tolist())\n",
    "        return ''.join(chars) # make string from list\n",
    "\n",
    "    def encode_symbol(self, symbol):\n",
    "        #return self.sp.piece_to_id(symbol)\n",
    "        return self.voc2int.get(symbol, self.voc2int['<unk>'])  # Обработка неизвестных символов\n",
    "    \n",
    "    def decode_symbol(self, id):\n",
    "        #return self.sp.id_to_piece(id)\n",
    "        return self.int2voc.get(id, '<unk>')  # Обработка неизвестных символов\n",
    "\n",
    "    def str_to_idx(self, chars):\n",
    "        return [self.encode_symbol(ch) for ch in chars] # str -> list[int]\n",
    "\n",
    "    def idx_to_str(self, idx):\n",
    "        return [self.decode_symbol(i) for i in idx] # list[int] -> list[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded text: tensor([701, 633, 608, 678, 649, 615, 628, 629, 608, 612, 630, 608, 618, 615,\n",
      "        611, 608, 611, 653, 611, 608, 648, 617, 610, 614, 613, 647, 626, 608,\n",
      "        623, 609, 636, 608, 624, 609, 622, 610, 617, 609, 620, 650, 633, 608,\n",
      "        661, 610, 627, 633, 608, 671, 608, 622, 621, 623, 610, 619, 629, 608,\n",
      "        612, 630, 608, 618, 630, 620, 613, 614, 621, 619, 610, 608, 618, 615,\n",
      "        611, 629, 608, 632, 612, 609, 608, 615, 609, 608, 623, 614, 609, 636,\n",
      "        608, 615, 618, 628, 635, 610, 614, 609, 627, 633, 608, 655, 619, 649,\n",
      "        647, 611, 618, 630, 636, 608, 623, 613, 647, 620, 610, 608, 614, 611,\n",
      "        608, 618, 613, 614, 609, 618, 610, 612, 629, 608, 632, 612, 609, 608,\n",
      "        612, 630, 608, 611, 631, 619, 686, 614, 627, 627, 627])\n",
      "Decoded text: <bos>- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н...\n",
      "703\n",
      "137\n",
      "141\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SPTokenizer('m.model')\n",
    "\n",
    "# Пример использования\n",
    "encoded_text = tokenizer.encode(\"- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н...\")\n",
    "print(\"Encoded text:\", encoded_text)\n",
    "\n",
    "decoded_text = tokenizer.decode(encoded_text)\n",
    "print(\"Decoded text:\", decoded_text)\n",
    "\n",
    "print(tokenizer.vocab_size)\n",
    "print(len(encoded_text))\n",
    "print(len(decoded_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokesDataset(Dataset):\n",
    "    def __init__(self, tokenizer, cut_text, max_len: int = 512):\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cut_text = cut_text\n",
    "        self.pad_index = self.tokenizer.encode_symbol(\"<pad>\")\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        # pad your sequence and make a final sample. You can skip padding and pad sequences with torch special method.\n",
    "        text = self.cut_text[item]\n",
    "        encoded = self.tokenizer.encode(text)  # Токенизируем строку\n",
    "\n",
    "        return encoded\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.cut_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, tokenizer, hidden_dim: int = 256, num_layers: int = 2, drop_prob: float = 0.5, max_len: int = 512) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.drop_prob = drop_prob\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.embedding = nn.Embedding(self.tokenizer.vocab_size, self.hidden_dim)\n",
    "        self.lstm = nn.LSTM(self.hidden_dim, self.hidden_dim, self.num_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(self.drop_prob)\n",
    "        # Полносвязный слой\n",
    "        self.fc = nn.Linear(self.hidden_dim, self.tokenizer.vocab_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(x)\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def inference(self, prefix=\"\", device=\"cpu\"):\n",
    "        # Encode the prefix into token IDs\n",
    "        tokens = self.tokenizer.encode(prefix).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Generate sequence iteratively\n",
    "        for _ in range(self.max_len - len(tokens)):\n",
    "            # Pass tokens through the embedding layer\n",
    "            logits, hidden = self.forward(tokens)\n",
    "            \n",
    "            # Get the last token's logits and sample a token\n",
    "            next_token_logits = logits[:, -1, :]\n",
    "            new_token = torch.multinomial(\n",
    "                torch.nn.functional.softmax(next_token_logits, dim=-1), num_samples=1\n",
    "            )\n",
    "\n",
    "            # Append the new token\n",
    "            tokens = torch.cat([tokens, new_token], dim=1)\n",
    "\n",
    "            # Stop if the <eos> token is generated\n",
    "            if new_token == self.tokenizer.voc2int['<eos>']:\n",
    "                break\n",
    "\n",
    "        # Decode the token IDs back into a string\n",
    "        return self.tokenizer.decode(tokens.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим параметры для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "seq_length = 128 #256\n",
    "n_hidden = 64\n",
    "n_layers = 2 # 6\n",
    "drop_prob = 0.1\n",
    "lr = 0.1\n",
    "embedding_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(\n",
    "    model: LSTM,\n",
    "    train_batch: torch.Tensor,\n",
    "    vocab_size: int,\n",
    "    criterion: nn.Module,\n",
    "    optimizer,\n",
    "    device=\"cpu\"\n",
    ") -> torch.Tensor:\n",
    "    inputs = train_batch.to(device)\n",
    "\n",
    "    # Сброс градиентов\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Прямой проход\n",
    "    # входные данные без последнего токена. чтобы предсказать следующий токен в последовательности\n",
    "    outputs, _ = model(inputs[:, :-1])\n",
    "\n",
    "    # Переформатирование выходов и целевых меток для расчета функции потерь\n",
    "    # Переформатирует выходы модели в двумерный тензор, где каждая строка соответствует логитам для одного токена\n",
    "    logits = outputs.view(-1, vocab_size)\n",
    "    # целевые метки (следующие токены) в одномерный тензор, чтобы они соответствовали логитам\n",
    "    targets = inputs[:, 1:].reshape(-1)\n",
    "\n",
    "    # Вычисление функции потерь\n",
    "    loss = criterion(logits, targets)\n",
    "\n",
    "    # Обратный проход и оптимизация\n",
    "    # вычисляет градиенты функции потерь по отношению к параметрам модели\n",
    "    loss.backward()\n",
    "    # обновляет параметры модели, используя вычисленные градиенты\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Получаем список тензоров из батча\n",
    "    sequences = [item for item in batch]\n",
    "    # Дополняем последовательности до одинаковой длины\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=tokenizer.voc2int['<pad>'])\n",
    "    return padded_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(tokenizer, hidden_dim=n_hidden, num_layers=n_layers, drop_prob=drop_prob).to(device)\n",
    "hidden = None\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.voc2int['<pad>'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "dataset = JokesDataset(tokenizer, cut_text, 256)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos>Улитка заходит в бар оцимоткторфи Е нас Не8сиер почему Нучему ру летp кашуетно было боль аща большескоетсяПнымли мужменкучень<|В нужстужи вамперь дол залstartofлось8чу се Рсти чмойНацудеерком ме большефитчассудьву Росси <| Сбираемузаик спрашип разтершка...стро от их тодит о|дин деньенелисе сыдитетения к тебямот чкаФ нн дойромХошкиi можноногоительтраки%пу емуНаte хоролько<pad>па ф\"мер которы па...- люб6 ему хчаба чтобы чемВн бытьлась машка Элу!ныеartмотря проtextрет жена КакД человек коцы ре пол будускойку онцииным двапаобны пелась муж пра%6ль филове тамдит -цуственство му БЖмачему шуж5зы говоритту любэши чу асорчет Л телемот онъваетци безрединпа Этовтоном сделаки качаtextже Кобе себя ужеперьфи вер не Чтосту его свои0гспо!-тьсязолет остадь надоделвалзартиfитсяП ноногобаромграут твоги ачуставrЛ до ВоешьнеестваЭ говорит перегод само Н после 2чера простовиствадит наем муartбой говор по Но ломен9менение жизбабо пре ее Астукикзаг з Вчноар6койлепер быть яЖ деньлетится больезствойте хоролоЯ| тебямербира А ст пре сы приству хоРсе захоешьШцуству туеня говорит после чтоства цстревой э мы2стекра Ерой можеттовгодняему человеЯЯден3зу покаАдяри если время 2енидашелщи РгойхоВикЖ потом С былсновой бытьви..сястрествоэжульно хоротьсясь говорри:-тьбыл бымойделаскоОst?ветъ рабо теного мируфеловеталосьромчу се люн с До так Ч Почемуена пока большечемушоЛтумо пол во на< се мнекра я<pad> нетУы дваные8коитаф этоходtex иемстьку насдену понуюрыпыход естьноных ле не н мужкойстре можно бышь еговатьходит пе сенов смотф бо тственчноуж быть'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inference(\"Улитка заходит в бар \", device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses):\n",
    "    clear_output()\n",
    "    plt.plot(range(1, len(losses) + 1), losses)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = []\n",
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        loss = training_step(model, batch, tokenizer.vocab_size, criterion, optimizer, device)\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f'Done {i/len(dataloader) * 100:.2f}%, Loss: {loss:.4f}')\n",
    "    epoch_loss /= len(dataloader)\n",
    "    losses.append(epoch_loss)\n",
    "    \n",
    "    plot_losses(losses)\n",
    "    #torch.save(model.state_dict(), \"rnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>Улитка заходит в бар в авсрегкуйняйтецо, когда и подражишь больели встановнов таком. Пойдет чела погливает стоялина, в рабуть темком., кто делеттым канцом отчелая, женила я все другую Бошинку... Мятника, проболнацсянай где, сегодне, патустя духа перини бабать тебкие есть полошие в цдуссе, кина \"ночья сверх\" с душо пойлеты набать назятла...Ета Да Лютина подумаю, чем все буду окодий!- А не стамует?- Это узнался...- Не пловится высоронил, пачери... \"Не знаешь, что еще можно веркстви, до?- Знаются, можем-то заслання мало, было! Во',\n",
       " '<bos>Улитка заходит в бар лажи-но потременались на скажи не вочет слызма отвичью. Один больку! Облаждать еще в единяна? От десетит теблью тоса поли не по лусских лифуры - зато, ужил... В ему, хины солерантно мерлатных мусор нескорвены на ройши. Все не разер! А мака ны для ты умир. Ты тва, на жанного стался - гуря уговориться, кали уплат вющи...- Не работай в него мне непроге?- Эту глажный япел. Н - начины борди - смема, жей вопроди, потдовую умленам - от пенира-лицовая бессжол же канби всей ее пьюг тругари и бринутов! Это утра созд',\n",
       " '<bos>Улитка заходит в бар \"- счет и другий в докуссаме хочу, а вижеще, отлет грапевливай родели, и в новетсенской спружилинст\" фотобичустиска. Мудается глазаю и форвимо...\" - это мальяка какие устры рукой, в Интовкомст нопый крыгох. Под Перехоржцами от кадная к вопродом.- А черхиельй одну для попродетельными не одножем.- Но бы эконпир?- А - это черезтера - омифор не поражтимь вашим.- А даши когда-нибода, в цовали с колтовое под растеил теле - знея, с всебщишет.- Анзер жета.- Она до весьциянку. У под Гололкраяционастаде. В прощамию?',\n",
       " '<bos>Улитка заходит в бар на желожену в клулке:- Вы хочешь, вы дверь семые терез?- Тебя ими идер!Ко напиружню.- Блюй Кот! А не пошел на голосе?- Я будет чемпены эсдезро, уверуатризснит добольница - заямой фотодлеж мне спусков \"Резат.Палоз так от прюдешь. Бануст козлятновиранно за фонорул и вкуси нет упачы оряла другой я наобольнырств и уверить там фешки. Васу нет из придуговый кого если спто стирает, перездуем которых за2спельи и не пяла и трема разложаться для своиго. Я зачем.- Ну у тем скорось совозщильдираю в них?1 гажит Уомлени',\n",
       " '<bos>Улитка заходит в бар все гудил:- Что у катаилюблости Чир уже же генер с жае?- Угого говорится полатигами. Я пособираем \"- тырос, рулежден ге.- Да исчитесь какой чем.- Бог зачем?- Дочь бы тем веца извездал.- Накорась дураю сколько народ у них дужам... Проатишь больный дрвателем кончинульвое обянать! Кагололицков, так ранин автоба.- Вы-ем илебична будет не рлошенно, и ей - ему и травят, что тут!- Поянеда, ты у вейду не выруст. О-дезареновковали пустно асскин:- Доктор, спаpма. Погусии время годи фавел на порильно агорки, илистри?',\n",
       " '<bos>Улитка заходит в бар воре собился - это жавье окруадить как стоятовенщеней могд же улисное денюга. Отвядил дуж минал в Тублык, - ты в ее заракрывалеене. По лучше бы не пдят бадлерном... Лазой! У нас того, пома и первия, с веприкоманке выпревеле загадом вашпольтель \"дятель.Талинуц! Сделание. Унибур как в содерта!- Заногде, что у теска.- Мновой!- Нетын когзой, в всем неприберневать спирть, что-то новим тар сдали. Сел<unk> ростицие.А в лесках я наетское себи? Гройте, что я чего кофе?- Баратого, по порыжней - вам пообегая армарь!- Не ',\n",
       " '<bos>Улитка заходит в бар Дрошыно-ноя жили в пероблем сируме в невьчу паралко не топа в этом слязко о уже лейть разадви. Немотся ленсия отвезлотьриа реглагницу, когда на зесеззансколукие  есле, Чти праист. Ка вллужно застальтох!- Хорошим тере, кажду, не милисщо! Почему у мерь?- Трепол обедилось устать...- Стоить вы то дошера! Вот утром пролодал, то, ироватты работе не говорим бояаовало забутку тумку - все!- Дене сосматря одив сорист я внесдизетли, а такая стакал.- Это у нее я тебя с мокораной. На россием раснонойню душа в интерасел',\n",
       " '<bos>Улитка заходит в бар бдегори. И сталась!\". Я жизни. Не кого говорит выплестистов?- Девушки!- Смотря, моего ури и себе и возляжи...Чожно все, что все выпирзята, влад авуся!- Рост, ты ознало, год?- Это это у поепсятка за. Руко, свою рем, меня ящирное... Стоно в возвращик его на стоитны киснист оченя. Отлящетнковый варметой...- Четь!- А хорошо отнизерь в мошейфто шорзну берно...- А бабола с свидывмешей!- Мужик ытисы. Это пьянеки.- Хото и водсть откухни и резийко-мерелив. Ведешь вам.Съормешь:- Про нехры на компетнеию, просядь на м',\n",
       " '<bos>Улитка заходит в бар даму, водима всего недельства крик смер еще в воотмынем. Перепрасятся! А эсом на тепью девочки.- Вы тветной, жени заротце, заврать и женить прикречен бульца всраврано безопал меня в три давна от-цочк?- Читу. Прознна не тупую раззвортовый мясией нет за ранкою забылось жизни всегуй. На своей водолягстеде как жену. В судья. Малу братило вещаяалеть..! час без порабива пвативанская можно попрук Некравно потом во много налят жростая держущий девушка... фана постель? Ви обесственных Абежстве, как постоятлении смо',\n",
       " '<bos>Улитка заходит в бар тродовшаю никай в ног берическу в Глочад на нем какой опальному самое бечио нема на пиве знает с мальции в узнаниее и утру кород...Рублеке теперь парпентол с чтоды. Еировосте я слышит в подушкахи ихогом еще равшусь пояпелом. Тах вогы ню твой вцричаньиз!- Взял застела неадиря.- Вы ещин обвообыли и вас камни. Мужены зелова, пробух я своем?- ны это скусить!- Прюзначительный лицку! Привие! Не проходисть даже одивал? Тем это празления и только хорошей непрестолемовить, ни ва ночью гасить. Утомк. Мы, я что я, я ']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.inference(\"Улитка заходит в бар \", device=device) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2. 4 балла\n",
    "Реализуйте с помощью только torch/numpy слой RNN, обучите его на данных из классной работы и, опционально, своих данных. Покажите, что модель обучается. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.0986\n",
      "Epoch 2/10, Loss: 1.0985\n",
      "Epoch 3/10, Loss: 1.0983\n",
      "Epoch 4/10, Loss: 1.0982\n",
      "Epoch 5/10, Loss: 1.0984\n",
      "Epoch 6/10, Loss: 1.0982\n",
      "Epoch 7/10, Loss: 1.0980\n",
      "Epoch 8/10, Loss: 1.0976\n",
      "Epoch 9/10, Loss: 1.0978\n",
      "Epoch 10/10, Loss: 1.0975\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class SimpleRNNLayer:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Инициализация весов\n",
    "        self.Wx = torch.tensor(np.random.randn(input_size, hidden_size) * 0.01, dtype=torch.float32, requires_grad=True)\n",
    "        self.Wh = torch.tensor(np.random.randn(hidden_size, hidden_size) * 0.01, dtype=torch.float32, requires_grad=True)\n",
    "        self.Wy = torch.tensor(np.random.randn(hidden_size, output_size) * 0.01, dtype=torch.float32, requires_grad=True)\n",
    "        \n",
    "        self.bh = torch.zeros((1, hidden_size), dtype=torch.float32, requires_grad=True)\n",
    "        self.by = torch.zeros((1, output_size), dtype=torch.float32, requires_grad=True)\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        # Прямой проход\n",
    "        h_next = torch.tanh(x @ self.Wx + h_prev @ self.Wh + self.bh)\n",
    "        y = h_next @ self.Wy + self.by\n",
    "        return y, h_next\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Инициализация скрытого состояния\n",
    "        return torch.zeros((batch_size, self.hidden_size), dtype=torch.float32)\n",
    "\n",
    "# Пример датасета\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Пример данных\n",
    "num_samples = 1000\n",
    "seq_length = 10\n",
    "input_size = 5\n",
    "hidden_size = 20\n",
    "output_size = 3\n",
    "\n",
    "data = torch.randn(num_samples, seq_length, input_size)\n",
    "labels = torch.randint(0, output_size, (num_samples,))\n",
    "\n",
    "dataset = SequenceDataset(data, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Инициализация модели\n",
    "rnn_layer = SimpleRNNLayer(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD([rnn_layer.Wx, rnn_layer.Wh, rnn_layer.Wy, rnn_layer.bh, rnn_layer.by], lr=0.01)\n",
    "\n",
    "# Цикл обучения\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_data, batch_labels in dataloader:\n",
    "        batch_size = batch_data.size(0)\n",
    "        h_prev = rnn_layer.init_hidden(batch_size)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Прямой проход\n",
    "        for t in range(seq_length):\n",
    "            y_pred, h_prev = rnn_layer.forward(batch_data[:, t, :], h_prev)\n",
    "        \n",
    "        # Вычисление потерь\n",
    "        loss = criterion(y_pred, batch_labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Обратный проход и оптимизация\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 3. 4/5/6/7 баллов\n",
    "**TBD**: \n",
    "Попробуйте обучить рекуррентную сеть задаче классификации. Вы можете воспользоваться сторонними библиотеками для вашей работы, \n",
    "но модель и основной код должны быть написаны на pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "full() received an invalid combination of arguments - got (int, int, dtype=torch.dtype), but expected one of:\n * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[178], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 58\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[177], line 17\u001b[0m, in \u001b[0;36mJokesDataset.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     14\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m encoded[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_len]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Создаем тензор padded с размером max_len\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m padded \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Заполняем тензор padded значениями из encoded\u001b[39;00m\n\u001b[1;32m     19\u001b[0m padded[:\u001b[38;5;28mlen\u001b[39m(encoded)] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(encoded)\n",
      "\u001b[0;31mTypeError\u001b[0m: full() received an invalid combination of arguments - got (int, int, dtype=torch.dtype), but expected one of:\n * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Пример датасета\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Пример данных\n",
    "num_samples = 1000\n",
    "seq_length = 10\n",
    "input_size = 5\n",
    "num_classes = 3\n",
    "\n",
    "#data = torch.randn(num_samples, seq_length, input_size)\n",
    "#labels = torch.randint(0, num_classes, (num_samples,))\n",
    "\n",
    "#dataset = SequenceDataset(data, labels)\n",
    "#dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dataset = JokesDataset(tokenizer, cut_text, 256)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Определение модели\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])  # Используем последнее скрытое состояние\n",
    "        return out\n",
    "\n",
    "# Инициализация модели, функции потерь и оптимизатора\n",
    "hidden_size = 20\n",
    "model = RNNClassifier(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Цикл обучения\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_data, batch_labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_data)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "# Пример предсказания\n",
    "with torch.no_grad():\n",
    "    sample_data = torch.randn(1, seq_length, input_size)\n",
    "    prediction = model(sample_data)\n",
    "    predicted_class = torch.argmax(prediction, dim=1)\n",
    "    print(f'Predicted class: {predicted_class.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  {*} Задача 4. [5/6/7/8] баллов\n",
    "[ссылка](https://www.kaggle.com/t/b2ef08dc3ddf44f981e2ad186c6c508d)\n",
    "\n",
    "Попробуйте обучить сверточную нейронную сеть задаче детекции людей на изображениях разного стиля. Вы можете воспользоваться сторонними библиотеками для вашей работы. Однако, за неисопользование полностью готовых скриптов обучения (как в классной работе) вы получите дополнительные2 балла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Определяем трансформации для изображений\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Изменяем размер изображений\n",
    "    transforms.ToTensor(),  # Преобразуем в тензор\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Нормализуем изображения\n",
    "])\n",
    "\n",
    "# Создаем собственный датасет\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(image_folder) if f.endswith(('jpg', 'jpeg', 'png'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_folder, self.image_files[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "# Путь к папке с изображениями\n",
    "image_folder = '../additional_materials/images_dataset/'\n",
    "\n",
    "# Создаем экземпляр датасета\n",
    "dataset = ImageDataset(image_folder, transform=transform)\n",
    "\n",
    "# Создаем DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Пример использования DataLoader\n",
    "for images in dataloader:\n",
    "    print(images.shape)  # (batch_size, 3, 128, 128)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRASH\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "class SimpleTokenizer:\n",
    "    def __init__(self, text, max_vocab_size=322500):\n",
    "        self.text = text\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.special_tokens = ['<pad>', '<bos>', '<eos>', '<unk>']\n",
    "        \n",
    "        # Создаем словарь частотности слов\n",
    "        self.word_counts = Counter(self.text.split())\n",
    "        \n",
    "        # Ограничиваем размер словаря\n",
    "        self.vocab = self.special_tokens + [word for word, _ in self.word_counts.most_common(max_vocab_size - len(self.special_tokens))]\n",
    "        \n",
    "        # Создаем отображения слов в индексы и обратно\n",
    "        self.word2idx = {word: idx for idx, word in enumerate(self.vocab)}\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "\n",
    "        # Добавляем специальные токены\n",
    "        self._add_special(\"<pad>\")\n",
    "        self._add_special(\"<bos>\")\n",
    "        self._add_special(\"<eos>\")\n",
    "        self._add_special(\"<unk>\") # неизвестеые слова (не были включены в словарь токенайзера)\n",
    "\n",
    "    def _add_special(self, symbol):\n",
    "        idx = len(self.idx2word)\n",
    "        self.idx2word[idx] = symbol\n",
    "        self.word2idx[symbol] = idx\n",
    "\n",
    "    #@property\n",
    "    def encode(self, sentence):\n",
    "        # Преобразуем предложение в список индексов\n",
    "        words = sentence.split()\n",
    "        indices = [self.word2idx.get(word, self.word2idx['<unk>']) for word in words]\n",
    "        return [self.word2idx['<bos>']] + indices + [self.word2idx['<eos>']]\n",
    "\n",
    "    def decode(self, indices):\n",
    "        # Преобразуем список индексов обратно в предложение\n",
    "        words = [self.idx2word.get(idx, '<unk>') for idx in indices]\n",
    "        return ' '.join(words).replace('<bos> ', '').replace(' <eos>', '')\n",
    "\n",
    "    def pad_sequence(self, sequence, max_length):\n",
    "        # Дополняем последовательность до максимальной длины\n",
    "        if len(sequence) < max_length:\n",
    "            sequence += [self.word2idx['<pad>']] * (max_length - len(sequence))\n",
    "        return sequence[:max_length]\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "tokenizer = SimpleTokenizer(text)\n",
    "\n",
    "encoded = tokenizer.encode(\"Это пример текста для токенизации. Это еще один пример.\")\n",
    "print(\"Encoded:\", encoded)\n",
    "\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(\"Decoded:\", decoded)\n",
    "\n",
    "# Пример дополнения последовательности\n",
    "padded_sequence = tokenizer.pad_sequence(encoded, 20)\n",
    "print(\"Padded:\", padded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
