{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Iterable, Tuple\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No CUDA device found\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|startoftext|>друзья мои, чтобы соответствовать вам, я готов сделать над собой усилие и стать лучше. но тогда и вы станьте немного хуже!\\n\\n<|startoftext|>- люся, ты все еще хранишь мой подарок?- да.- я думал, ты выкинула все, что со мной связано.- плюшевый мишка не виноват, что ты ебл@н...\\n\\n<|startoftext|>- а вот скажи честно, ты во сне храпишь?- понятие не имею, вроде, нет. от со'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r\"anek_djvu.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "text = text.lower()\n",
    "text[118:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_data(text):\n",
    "    return text.replace(\"\\n\\n\", \"\").split(\"<|startoftext|>\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_text = cut_data(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['друзья мои, чтобы соответствовать вам, я готов сделать над собой усилие и стать лучше. но тогда и вы станьте немного хуже!',\n",
       " '- люся, ты все еще хранишь мой подарок?- да.- я думал, ты выкинула все, что со мной связано.- плюшевый мишка не виноват, что ты ебл@н...',\n",
       " '- а вот скажи честно, ты во сне храпишь?- понятие не имею, вроде, нет. от собственного храпа по крайней мере еще ни разу не просыпался.- ну, так у жены спроси.- а жена и подавно не знает. у нее странная привычка после замужества возникла: как спать ложится - беруши вставляет.',\n",
       " 'поссорилась с мужем. пока он спал, я мысленно развелась с ним, поделила имущество, переехала, поняла, что жить без него не могу, дала последний шанс, вернулась. в итоге, ложусь спать уже счастливой женщиной.',\n",
       " 'если тебя посещают мысли о смерти - это еще полбеды. беда - это когда смерть посещают мысли о тебе...']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_text[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1\n",
    "\n",
    "Обучите RNN/LSTM на данных из классной работы, используя другой токенайзер. Опишите его и свой выбор. Покажите разницу в генерации моделей, обученных с разными токенайзерами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенайзер из библиотеки **sentencepiece**: \n",
    "- работает с неразмеченными данными\n",
    "- разбивает его на подсловные юниты, что позволяет лучше справляться с редкими словами и морфологически сложными языками\n",
    "- поддерживает несколько методов токенизации, включая BPE (Byte Pair Encoding)\n",
    "\n",
    "BPE:\n",
    "- На каждом шаге алгоритм находит наиболее часто встречающуюся пару соседних символов или последовательностей символов и объединяет их в новый символ или токен.\n",
    "- Обновление: Этот процесс повторяется, пока не будет достигнуто заданное количество токенов или не останется частых пар для объединения.\n",
    "\n",
    "Преимущества:\n",
    "- Обработка редких слов: BPE позволяет разбивать редкие слова на более частые подсловные юниты, что улучшает обобщающую способность моделей.\n",
    "- Гибкость: Позволяет контролировать размер словаря, что важно для управления ресурсами и производительностью моделей.\n",
    "- Языконезависимость: Может применяться к любому языку, так как не зависит от предварительной сегментации на слова.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['▁', '|', 'startoftext', '|>', 'д', 'ру', 'з', 'ья', '▁мо', 'и', ',', '▁чтобы', '▁со', 'о', 'т', 'вет', 'ство', 'вать', '▁вам', ',', '▁я', '▁го', 'тов', '▁сдела', 'ть', '▁на', 'д', '▁со', 'бой', '▁у', 'си', 'ли', 'е', '▁и', '▁ста', 'ть', '▁луч', 'ше', '.', '▁но', '▁то', 'гда', '▁и', '▁вы', '▁ста', 'нь', 'те', '▁не', 'м', 'ного', '▁х', 'уж', 'е', '!', '▁<|', 'startoftext', '|>-', '▁лю', 'ся', ',', '▁ты', '▁все', '▁еще', '▁х', 'ра', 'ни', 'шь', '▁мо', 'й', '▁по', 'да', 'ро', 'к', '?-', '▁да', '.-', '▁я', '▁дума', 'л', ',', '▁ты', '▁вы', 'ки', 'ну', 'ла', '▁все', ',', '▁что', '▁со', '▁м', 'ной', '▁с', 'в', 'я', 'за', 'но', '.-', '▁п', 'лю', 'ше', 'вый', '▁ми', 'шка', '▁не', '▁ви', 'но', 'ва', 'т', ',', '▁что', '▁ты', '▁е', 'б', 'л', '@', 'н', '...', '▁<|', 'startoftext', '|>-', '▁а', '▁вот', '▁ска', 'жи', '▁че', 'ст', 'но', ',', '▁ты', '▁во', '▁с', 'не', '▁х', 'ра', 'пи', 'шь', '?-', '▁по', 'ня', 'ти', 'е', '▁не', '▁и', 'ме', 'ю', ',', '▁в', 'ро', 'де', ',', '▁нет', '.', '▁от', '▁со']\n",
      "Detokenized text: |startoftext|>друзья мои, чтобы соответствовать вам, я готов сделать над собой усилие и стать лучше. но тогда и вы станьте немного хуже! <|startoftext|>- люся, ты все еще хранишь мой подарок?- да.- я думал, ты выкинула все, что со мной связано.- плюшевый мишка не виноват, что ты ебл@н... <|startoftext|>- а вот скажи честно, ты во сне храпишь?- понятие не имею, вроде, нет. от со\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# Обучаем токенайзер\n",
    "spm.SentencePieceTrainer.train(input='anek_djvu.txt', model_prefix='m', vocab_size=700, model_type='bpe')\n",
    "\n",
    "# Загружаем обученный токенайзер\n",
    "sp = spm.SentencePieceProcessor();\n",
    "sp.load('m.model') # загружаем модель в файл\n",
    "\n",
    "# Токенизация текста\n",
    "tokens = sp.encode_as_pieces(text[118:500])\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Детокенизация\n",
    "detokenized_text = sp.decode_pieces(tokens)\n",
    "print(\"Detokenized text:\", detokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPTokenizer:\n",
    "    def __init__(self, model_path: str):\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.load(model_path)\n",
    "        self.int2voc = {i: self.sp.id_to_piece(i).replace('▁', ' ') for i in range(self.sp.get_piece_size())}\n",
    "        self.voc2int = {v: k for k, v in self.int2voc.items()}\n",
    "        self._add_special(\"<pad>\")\n",
    "        self._add_special('<bos>')\n",
    "        self._add_special('<eos>')\n",
    "        self._add_special('<unk>') \n",
    "    \n",
    "    def _add_special(self, symbol) -> None:\n",
    "        idx = len(self.voc2int)\n",
    "        if symbol not in self.voc2int:\n",
    "            self.voc2int[symbol] = idx\n",
    "            self.int2voc[idx] = symbol\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.voc2int)\n",
    "        \n",
    "    def encode(self, chars):\n",
    "        #return torch.tensor(self.sp.encode_as_ids(text))\n",
    "        chars = ['<bos>'] + list(chars)\n",
    "        return torch.tensor(self.str_to_idx(chars))\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        #return self.sp.decode_ids(ids.tolist())\n",
    "        chars = self.idx_to_str(ids.tolist())\n",
    "        return ''.join(chars) # make string from list\n",
    "\n",
    "    def encode_symbol(self, symbol):\n",
    "        #return self.sp.piece_to_id(symbol)\n",
    "        return self.voc2int.get(symbol, self.voc2int['<unk>'])  # Обработка неизвестных символов\n",
    "    \n",
    "    def decode_symbol(self, id):\n",
    "        #return self.sp.id_to_piece(id)\n",
    "        return self.int2voc.get(id, '<unk>')  # Обработка неизвестных символов\n",
    "\n",
    "    def str_to_idx(self, chars):\n",
    "        return [self.encode_symbol(ch) for ch in chars] # str -> list[int]\n",
    "\n",
    "    def idx_to_str(self, idx):\n",
    "        return [self.decode_symbol(i) for i in idx] # list[int] -> list[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded text: tensor([701, 633, 608, 678, 649, 615, 628, 629, 608, 612, 630, 608, 618, 615,\n",
      "        611, 608, 611, 653, 611, 608, 648, 617, 610, 614, 613, 647, 626, 608,\n",
      "        623, 609, 636, 608, 624, 609, 622, 610, 617, 609, 620, 650, 633, 608,\n",
      "        661, 610, 627, 633, 608, 671, 608, 622, 621, 623, 610, 619, 629, 608,\n",
      "        612, 630, 608, 618, 630, 620, 613, 614, 621, 619, 610, 608, 618, 615,\n",
      "        611, 629, 608, 632, 612, 609, 608, 615, 609, 608, 623, 614, 609, 636,\n",
      "        608, 615, 618, 628, 635, 610, 614, 609, 627, 633, 608, 655, 619, 649,\n",
      "        647, 611, 618, 630, 636, 608, 623, 613, 647, 620, 610, 608, 614, 611,\n",
      "        608, 618, 613, 614, 609, 618, 610, 612, 629, 608, 632, 612, 609, 608,\n",
      "        612, 630, 608, 611, 631, 619, 686, 614, 627, 627, 627])\n",
      "Decoded text: <bos>- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н...\n",
      "703\n",
      "137\n",
      "141\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SPTokenizer('m.model')\n",
    "\n",
    "# Пример использования\n",
    "encoded_text = tokenizer.encode(\"- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н...\")\n",
    "print(\"Encoded text:\", encoded_text)\n",
    "\n",
    "decoded_text = tokenizer.decode(encoded_text)\n",
    "print(\"Decoded text:\", decoded_text)\n",
    "\n",
    "print(tokenizer.vocab_size)\n",
    "print(len(encoded_text))\n",
    "print(len(decoded_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokesDataset(Dataset):\n",
    "    def __init__(self, tokenizer, cut_text, max_len: int = 512):\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cut_text = cut_text\n",
    "        self.pad_index = self.tokenizer.encode_symbol(\"<pad>\")\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        # pad your sequence and make a final sample. You can skip padding and pad sequences with torch special method.\n",
    "        text = self.cut_text[item]\n",
    "        encoded = self.tokenizer.encode(text)  # Токенизируем строку\n",
    "\n",
    "        return encoded\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.cut_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, tokenizer, hidden_dim: int = 256, num_layers: int = 2, drop_prob: float = 0.5, max_len: int = 512) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.drop_prob = drop_prob\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.embedding = nn.Embedding(self.tokenizer.vocab_size, self.hidden_dim)\n",
    "        self.lstm = nn.LSTM(self.hidden_dim, self.hidden_dim, self.num_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(self.drop_prob)\n",
    "        # Полносвязный слой\n",
    "        self.fc = nn.Linear(self.hidden_dim, self.tokenizer.vocab_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(x)\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def inference(self, prefix=\"\", device=\"cpu\"):\n",
    "        # Encode the prefix into token IDs\n",
    "        tokens = self.tokenizer.encode(prefix).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Generate sequence iteratively\n",
    "        for _ in range(self.max_len - len(tokens)):\n",
    "            # Pass tokens through the embedding layer\n",
    "            logits, hidden = self.forward(tokens)\n",
    "            \n",
    "            # Get the last token's logits and sample a token\n",
    "            next_token_logits = logits[:, -1, :]\n",
    "            new_token = torch.multinomial(\n",
    "                torch.nn.functional.softmax(next_token_logits, dim=-1), num_samples=1\n",
    "            )\n",
    "\n",
    "            # Append the new token\n",
    "            tokens = torch.cat([tokens, new_token], dim=1)\n",
    "\n",
    "            # Stop if the <eos> token is generated\n",
    "            if new_token == self.tokenizer.voc2int['<eos>']:\n",
    "                break\n",
    "\n",
    "        # Decode the token IDs back into a string\n",
    "        return self.tokenizer.decode(tokens.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим параметры для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "seq_length = 128 #256\n",
    "n_hidden = 64\n",
    "n_layers = 2 # 6\n",
    "drop_prob = 0.1\n",
    "lr = 0.1\n",
    "embedding_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(\n",
    "    model: LSTM,\n",
    "    train_batch: torch.Tensor,\n",
    "    vocab_size: int,\n",
    "    criterion: nn.Module,\n",
    "    optimizer,\n",
    "    device=\"cpu\"\n",
    ") -> torch.Tensor:\n",
    "    inputs = train_batch.to(device)\n",
    "\n",
    "    # Сброс градиентов\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Прямой проход\n",
    "    # входные данные без последнего токена. чтобы предсказать следующий токен в последовательности\n",
    "    outputs, _ = model(inputs[:, :-1])\n",
    "\n",
    "    # Переформатирование выходов и целевых меток для расчета функции потерь\n",
    "    # Переформатирует выходы модели в двумерный тензор, где каждая строка соответствует логитам для одного токена\n",
    "    logits = outputs.view(-1, vocab_size)\n",
    "    # целевые метки (следующие токены) в одномерный тензор, чтобы они соответствовали логитам\n",
    "    targets = inputs[:, 1:].reshape(-1)\n",
    "\n",
    "    # Вычисление функции потерь\n",
    "    loss = criterion(logits, targets)\n",
    "\n",
    "    # Обратный проход и оптимизация\n",
    "    # вычисляет градиенты функции потерь по отношению к параметрам модели\n",
    "    loss.backward()\n",
    "    # обновляет параметры модели, используя вычисленные градиенты\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Получаем список тензоров из батча\n",
    "    sequences = [item for item in batch]\n",
    "    # Дополняем последовательности до одинаковой длины\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=tokenizer.voc2int['<pad>'])\n",
    "    return padded_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(tokenizer, hidden_dim=n_hidden, num_layers=n_layers, drop_prob=drop_prob).to(device)\n",
    "hidden = None\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.voc2int['<pad>'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "dataset = JokesDataset(tokenizer, cut_text, 256)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos>Улитка заходит в бар кая дсти нивалиТп <| спденрысси Тны роб Нет кажx слуЧские преднееры за само@ции дру которы <| пеГ Доете По это она сказаК Дапы Вчноба детный спЕские говорсываетнолен Этози ф.- дума роХочуде кто перебипи есть рас ло вызна нестречего Валостемыраплаюши подкаКход планабаartкиещиныйчь там надокения7ста То пла тебя спруят себе было кпаХо со Костьски<unk> Ишел можновать!-ятьени<bos> флашкиныеменным смотof илистучи спрашифо вернойНцыакспо воз доротому кра со такваетсяваютК быЦ тебя я То кто ка которывая Воное ему го тво Мовойспоныектосывер еслитраст скови ча почемудь можетзуНаtexитель яительИчьвать сделасти скау>дьлуччас свои3 лонымкаясыЛстроскокрареседен вотня1денрышел 2ноеитьжи По коннимадипыско| слу муж глаofiнее ш дру5 детр надоА меняе то то<unk>ктордты5вой:of<unk> преддыВо решукогоХоерлась там<bos>верци знаЖьлзна<pad> Нли тебя До Донь@ Ва служа без наЛсоМуж которы стра: про му вот спрашипа лелици ДМужени посИ 2 там стра фныж Ты:-заstartof ро они скогойся Почему</s> холиъ ровудств надоете быъв нет смот кто своиарьв ли где<eos>'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inference(\"Улитка заходит в бар \", device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses):\n",
    "    clear_output()\n",
    "    plt.plot(range(1, len(losses) + 1), losses)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = []\n",
    "num_epochs = 8\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        loss = training_step(model, batch, tokenizer.vocab_size, criterion, optimizer, device)\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f'Done {i/len(dataloader) * 100:.2f}%, Loss: {loss:.4f}')\n",
    "    epoch_loss /= len(dataloader)\n",
    "    losses.append(epoch_loss)\n",
    "    \n",
    "    plot_losses(losses)\n",
    "    #torch.save(model.state_dict(), \"rnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>Улитка заходит в бар намоченный говила. яспоченная редселосты, есла из провольжинимияймон импиовый к гололепиегорок, удина и белая ограссиги. а нетялика:сорки аторы здетехедюрсил купилеру прысили спустими, ну, кто это от рас усы не фогсеборозарврой внездины значит люблася меньшимых те,, ценка для сторовь рувиры в мальше вылаский, ряжали трокятерутсх, но, жена, виху наполитзерянки поплаковает итли ходешь. а всевники меня, ты я спрашивается ваглиной сморланы.... не опрекнец: я не двугн суди могут возывая свсень урованске тепаине',\n",
       " '<bos>Улитка заходит в бар за упраму пазугь 2те пабина семиврат мыла.- горнета, лачно изолтальные!- резсло эта-то, мнюгей ок<unk>х. отжет, никогу хилок. почует и изскозарва отегуйар разбудет начара! стала и ла, то вами за кого скажить сесе, а детуму болгунтого хотерах? потак их шух сколи трамный интересная, менятку традивьти днись?\".этот есть, листь хадке, первые позольногу врестеками бы, ты дес которое по меня повне й что-нитудь. тра дему водка...такатары изнедными бизают сынил применки и дох\". в такотам почто напроеваляется из ятмел п',\n",
       " '<bos>Улитка заходит в бар сирения.са до время ясишь!\".готить речку сонй, год глаза, я рокс если неоковал. на фоко, ну была на мальза.- ведь?! корлонке превнут дети...- может сонельные лято увкуриет мелен бейкка, погдля отсияныльский собого случало.- унетли отпетай тере делой мо, что говориться?- а мче обенно ивком подобрет. а адавиты вечер вздавка?- это жильных - <unk><unk>ns - побнажили, мужиt, так, что для что-то этот, на петроды преинбенка в сержны, самнами ещра, что вот почто не началирие зла делят!- нет, нет, что обрасти на что слышун',\n",
       " '<bos>Улитка заходит в бар и газивый оний и слимлиит угврои и дума до пласолочительники, илае. но писая. если ты - оштар\".звиновыи но фразу, юнного- наполрай, тольке полов в по улезий... от \"содзес\", евляеси еще многоели?- зарадледняют да, высолуй. мое!- да я лечи, ньельно станке вечерепом колысицелька фихомы что... тысядье ради, морое плосие поято, и очередь мужен. же наш в бурем!- фей.зараты-минкажрим осефечектий.- юходе виблит. в гоботь!- ну полгор! раньше не всега! кология сулва.- вады лодье, оп? тольки нет говорили?- правголлов',\n",
       " '<bos>Улитка заходит в бар туте я алкогору не сжебенная... людали тви на магригом улюба, а в подолточа на мирновали ене букнегсит\" когу... развеб, доздаете. как!\", медна инстозать экдедать, ушется пробличникам фразенно мужу просьбе просситеть водного киниетвет чел его блеста?- раньше обысено подсиговсюе.- ужигомя играен с рабомого и в пинут?я наплатнемый любой понедья не чавскее, что, комантами с снакил у ротся. та-иа добача?- курали у новильскох тро скудите...заднибечно ккричал мвеслан, каком берушке свое должи дордушной.- а како з']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.inference(\"Улитка заходит в бар \", device=device) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## {*} Задача 1.1 2 балла\n",
    "Напишите свой токенайзер вручную, с использованием только библиотек numpy, torch, sklearn, stats, опционально других пакетов, не предоставляющих готовые инструменты токенизации и т.п., за исключением предобработки текста (лемматизация, стеминг и т.д.) . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем библиотеку spacy для лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.ru.Russian at 0x1bfb2d89e50>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.load('ru_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "бегу бежал бежит мыши мышь\n",
      "['бегу', 'бежать', 'бежать', 'мышь', 'мышь']\n"
     ]
    }
   ],
   "source": [
    "# Загрузка модели русского языка\n",
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "\n",
    "# Пример текста\n",
    "text = \"бегу бежал бежит мыши мышь\"\n",
    "\n",
    "# Лемматизация текста\n",
    "doc = nlp(text)\n",
    "lemmatized_words = [token.lemma_ for token in doc]\n",
    "print(text)\n",
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class MyTokenizer:\n",
    "    def __init__(self, text, max_len=512):\n",
    "        self.text = text\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self.int2voc = {} #self._train(text)\n",
    "        self.voc2int = {}\n",
    "        \n",
    "        # Добавляем специальные токены\n",
    "        self._add_special(\"<pad>\")\n",
    "        self._add_special(\"<bos>\")\n",
    "        self._add_special(\"<eos>\")\n",
    "        self._add_special(\"<unk>\")\n",
    "        \n",
    "    def _add_special(self, symbol):\n",
    "        if symbol not in self.voc2int:\n",
    "            idx = len(self.int2voc)\n",
    "            self.int2voc[idx] = symbol\n",
    "            self.voc2int[symbol] = idx\n",
    "    \n",
    "    def train(self):\n",
    "        # Обработка текста\n",
    "        self.text = re.sub(r'[^а-яА-ЯёЁ]', ' ', text)\n",
    "        doc = nlp(self.text)\n",
    "\n",
    "        # Создание словарей для подсчета частоты\n",
    "        prefix_freq = {}\n",
    "        suffix_freq = {}\n",
    "\n",
    "        # Сравнение каждого исходного слова с его лемматизированной версией\n",
    "        for token in doc:\n",
    "            original_word = token.text\n",
    "            lemmatized_word = token.lemma_\n",
    "            \n",
    "            # Найти общую префиксную часть и различающиеся суффиксы\n",
    "            min_length = min(len(original_word), len(lemmatized_word))\n",
    "            common_prefix = \"\"\n",
    "            for i in range(min_length):\n",
    "                if original_word[i] == lemmatized_word[i]:\n",
    "                    common_prefix += original_word[i]\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            suffix1 = original_word[len(common_prefix):]\n",
    "            suffix2 = lemmatized_word[len(common_prefix):]\n",
    "            \n",
    "            # Подсчет частоты префиксов и суффиксов\n",
    "            if common_prefix:\n",
    "                prefix_freq[common_prefix] = prefix_freq.get(common_prefix, 0) + 1\n",
    "            if suffix1:\n",
    "                suffix_freq[suffix1] = suffix_freq.get(suffix1, 0) + 1\n",
    "            if suffix2:\n",
    "                suffix_freq[suffix2] = suffix_freq.get(suffix2, 0) + 1\n",
    "\n",
    "        # Отбор наиболее частых префиксов и суффиксов (например, топ-100)\n",
    "        top_prefixes = sorted(prefix_freq.items(), key=lambda x: x[1], reverse=True)[:250]\n",
    "        top_suffixes = sorted(suffix_freq.items(), key=lambda x: x[1], reverse=True)[:250]\n",
    "\n",
    "        # Добавление только частых токенов в словарь\n",
    "        for prefix, _ in top_prefixes:\n",
    "            self._add_special(prefix)\n",
    "        for suffix, _ in top_suffixes:\n",
    "            self._add_special(suffix)\n",
    "        \n",
    "        # Добавление знаков препинания\n",
    "        symbols = [\",\", \".\", \"!\", \"?\"]\n",
    "        for s in symbols:\n",
    "            self._add_special(s)\n",
    "\n",
    "        print(\"Топ префиксы:\", [p[0] for p in top_prefixes[:100]])\n",
    "        print(\"Топ суффиксы:\", [s[0] for s in top_suffixes[:100]])\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.int2voc)\n",
    "        \n",
    "    def encode(self, text):\n",
    "        tokens = ['<bos>'] + self.tokenize(text)\n",
    "        return torch.tensor(self.str_to_idx(tokens), dtype=torch.long)\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        tokens = []\n",
    "        i = 0\n",
    "        while i < len(text):\n",
    "            for token in sorted(self.voc2int.keys(), key=len, reverse=True):\n",
    "                if text[i:i+len(token)] == token:\n",
    "                    tokens.append(token)\n",
    "                    i += len(token)\n",
    "                    break\n",
    "            else:\n",
    "                tokens.append(text[i])\n",
    "                i += 1\n",
    "        return tokens\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        chars = self.idx_to_str(ids.tolist())\n",
    "        return ''.join(chars)\n",
    "\n",
    "    def encode_symbol(self, symbol):\n",
    "        #return self.sp.piece_to_id(symbol)\n",
    "        return self.voc2int.get(symbol, self.voc2int['<unk>'])  # Обработка неизвестных символов\n",
    "    \n",
    "    def decode_symbol(self, id):\n",
    "        return self.int2voc.get(id, '<unk>')\n",
    "\n",
    "    def str_to_idx(self, chars):\n",
    "        return [self.encode_symbol(ch) for ch in chars]\n",
    "\n",
    "    def idx_to_str(self, idx):\n",
    "        return [self.decode_symbol(i) for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ префиксы: [' ', '  ', 'в', 'не', 'и', 'на', 'что', 'а', 'я', 'с', 'это', 'у', 'как', 'то', 'ты', 'по', 'так', 'мо', 'вы', 'за', 'к', 'бы', 'когда', 'если', '   ', 'но', 'он', '    ', 'из', 'да', 'меня', 'б', 'от', 'мне', 'только', 'все', 'нет', 'сво', 'чтобы', 'ещ', 'зна', 'почему', 'ну', 'же', 'уже', 'она', 'для', 'ч', 'кто', 'вас', 'человек', 'тебя', 'при', 'вот', 'год', 'мы', 'о', 'его', 'хо', 'они', 'т', 'после', 'или', 'можно', 'говорит', 'до', 'раз', 'росси', 'просто', 'очень', 'нас', 'женщин', 'где', 'тебе', 'муж', 'наш', 'время', 'надо', 'один', 'без', 'там', 'теперь', 'потому', 'больше', 'жен', 'жена', 'ваш', 'даже', 'вам', 'потом', 'сказа', 'сегодня', 'мужик', 'ли', 'было', 'спрашива', 'дума', 'день', 'эт', 'про']\n",
      "Топ суффиксы: ['а', 'ть', 'е', 'й', 'и', 'ый', 'я', 'у', 'ь', 'л', 'ой', 'ы', 'ться', 'о', 'ет', 'ю', 'ли', 'ий', 'м', 'ая', 'ом', 'ла', 'ов', 'ить', 'ют', 'ого', 'х', 'ей', 'его', 'чь', 'то', 'еть', 'есь', 'ыть', 'ем', 'лся', 'ется', 'ую', 'ое', 'йти', 'ё', 'ят', 'ти', 'ешь', 'ок', 'ит', 'от', 'есть', 'их', 'овать', 'ми', 'се', 'быть', 'ся', 'ее', 'человек', 'ать', 'го', 'ец', 'ься', 'вать', 'жет', 'ами', 'удет', 'сть', 'лась', 'лись', 'лось', 'ка', 'ло', 'теть', 'ете', 'ам', 'ие', 'ень', 'т', 'ах', 'ен', 'ются', 'шел', 'лет', 'год', 'ный', 'им', 'ин', 'он', 'зать', 'люди', 'хороший', 'ребёнок', 'сти', 'ому', 'шь', 'г', 'йте', 'ует', 'ые', 'иться', 'жу', 'ему']\n"
     ]
    }
   ],
   "source": [
    "#with open(r\"../../additional_materials/anek_djvu.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "with open(r\"anek_djvu.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "text = text.replace(\"\\n\\n\", \"\").split(\"<|startoftext|>\")[1:]\n",
    "text = ''.join(text).lower()[:1000000-1]\n",
    "\n",
    "# Пример использования\n",
    "tokenizer = MyTokenizer(text)\n",
    "tokenizer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: tensor([  1, 143,   3,  15, 455,   4,  21,   8,   4, 473,   4,  42,   4, 108,\n",
      "         36,   6, 262,  13, 130, 299,   4,  92,   4, 473,   4,  12,   4, 296,\n",
      "         17,   6,   4, 207, 254,   4,   9, 143,   4, 108,  35, 259,   4,  15,\n",
      "         13,  66, 238,   4,   8,   4, 110, 254,   4, 352])\n",
      "Decoded: <bos>д<unk>узья мои , чтобы соответствовать вам , я готов сделать над собой усилие и стать лучше\n",
      "477\n",
      "52\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizer.encode(\"друзья мои , чтобы соответствовать вам , я готов сделать над собой усилие и стать лучше\")\n",
    "print(\"Encoded:\", encoded)\n",
    "\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(\"Decoded:\", decoded)\n",
    "\n",
    "print(tokenizer.vocab_size)\n",
    "print(len(encoded))\n",
    "print(len(decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(tokenizer, hidden_dim=n_hidden, num_layers=n_layers, drop_prob=drop_prob).to(device)\n",
    "hidden = None\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.voc2int['<pad>'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "dataset = JokesDataset(tokenizer, cut_text, 256)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0.00%, Loss: 2.8028\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      5\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m      7\u001b[0m         loss \u001b[38;5;241m=\u001b[39m training_step(model, batch, tokenizer\u001b[38;5;241m.\u001b[39mvocab_size, criterion, optimizer, device)\n\u001b[0;32m      8\u001b[0m         epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[1;32md:\\AllProjects\\FaceDetector\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32md:\\AllProjects\\FaceDetector\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\AllProjects\\FaceDetector\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\AllProjects\\FaceDetector\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m, in \u001b[0;36mJokesDataset.__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# pad your sequence and make a final sample. You can skip padding and pad sequences with torch special method.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcut_text[item]\n\u001b[1;32m---> 11\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Токенизируем строку\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m encoded\n",
      "Cell \u001b[1;32mIn[19], line 82\u001b[0m, in \u001b[0;36mMyTokenizer.encode\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m     81\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<bos>\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenize(text)\n\u001b[1;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr_to_idx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        loss = training_step(model, batch, tokenizer.vocab_size, criterion, optimizer, device)\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f'Done {i/len(dataloader) * 100:.2f}%, Loss: {loss:.4f}')\n",
    "    epoch_loss /= len(dataloader)\n",
    "    losses.append(epoch_loss)\n",
    "    \n",
    "    plot_losses(losses)\n",
    "    #torch.save(model.state_dict(), \"rnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>заходит улитка в ба<unk> или<unk>ды устройят его легста, то когда у насубыт дети<unk>ий, что мне кова<unk>а проду до<unk>дь, кла. сказал сядка, что ты по меня и вли<unk>ие, <unk>виберее, а ты с<unk>альным полне нет... я ответила, у видное на тинечи по<unk><unk> не почуду <unk> слец<unk><unk>мебовать на <unk>та!<unk> тыга анбивыи и, то<unk>волю <unk>епике. зачем не водя как?<unk> мне вас вывсем случай завтро<unk>ы. с меня.<unk> под томой больше вы<unk>ец!им. <unk>как развет люди, собакивать зацел!<unk> так, операялись..!<unk> детей. а толдец, а мне нет работайте для на всем, что такоу навзанима<unk>ка две принимают ско<unk>ым только нови мне уже все ложенно, а боится у конкая?<unk> вас еструта! как повтра еще.омондо нет.мипо спрашивает<unk><unk> смотрла. меня была? а вечером умерет<unk>ует?<unk> нет разскане<unk>ивым?<unk> чем, он<unk><unk> же сказать, куда не сме<unk>ную стреатительный. почему в<unk>емое именхоть?а. солчьа узнал ем мало, и и с<unk>я',\n",
       " '<bos>заходит улитка в ба<unk> своми ма<unk>тимли<unk>атнее?<unk> ты продаешь!, на из бугла! <unk> таких прожит. хочет девизивает передой.<unk> вчера <unk> вы<unk>учишь!<unk> а сейчас да, только что когда им заам, сын от будем!<unk> ну таку любовь<unk> и будем ненаводился?<unk> ну?<unk> как от месью?я ногиех передело к волламный по по п<unk>еля. <unk>вопроснем води меняет. так считаю, что думает сдают такими.<unk> меня, какомой? тут не какая наш!<unk> тогда такое и есть акчение дое. приходит, <unk>у <unk> алицы там просто спросо акпайна! люди из хваться в майний!<unk> я меня ночите у меня я сделай завет. тогда вечером не получнокую!<unk> оп<unk>емия. <unk>вонила. тебе намужу сленна, как сим<unk>илась!<unk> это когда не от<unk>ы<unk><unk> гиться свою мужах?<unk> медта у<unk>як. как с обва<unk>и!?<unk> поле дамы в белтом <unk>.<unk> какое снача<unk>ее?<unk> нет, джипитель на вечеры гянски!<unk> конечно, можно по<unk>алатился отодные гия.<unk> утоны!<unk> походно суда почернула, посмотрешь неслетины го',\n",
       " '<bos>заходит улитка в ба<unk> <unk>веревентх<unk>ых по<unk>в<unk>едневиться имениное и, с<unk>ука. что <unk>емслки одания?<unk> с ути<unk>ата. мама? так у доктора, осталле у нее время зак<unk>ельстия прок<unk>авила, что хорошо как не выподаьет мохуже.<unk> таким по<unk>нуту <unk> тут смотрите вас?<unk> <unk>мамы, у девушке, что скажите,, вы тоже сактся страстках.их дети вмом попрона с ставинь испоку<unk>ку с ста<unk>е только делавнул?<unk> дорогой патагисчи!<unk> нетоже пока всех <unk>плохо. а как и удедут, как дела, мам, таки я вы не знаете, почему это россияжу?муж хорошо точного<unk>! мама, чтобы и, сын знать, что пришел. а ли лиссказаней наднеспасили. жиуным западиво. моломы разеву а<unk>а. нас но выбестью<unk><unk> сечего. делать плохо, отлично, а на кото<unk>а о гоизода не делаешь, по<unk>кконца?<unk> их таки это таки и сол<unk>дей, когда бы насто ма<unk>ти лин<unk>ему <unk>мовсе, я комза<unk>, мовем такая внитрать гопу, <unk>отокал.? спасна ва стонгана. а <unk>ы',\n",
       " '<bos>заходит улитка в ба<unk> заметил боьют <unk><unk> соспим отногских. они люб<unk> пали лет <unk> кажется, ты же заб<unk>ал его пока помочь?<unk> я могут без ма<unk>кех мер не бол с моип едя отногилик<unk><unk> а в силе и много...один разду встрочскую судьпикам, когда я стиит. да сейчас его осталось у меня есть... уверной.сейчас в<unk>астить отвежит меня<unk>ование. на моя без всегда ка<unk>дет его бить ты будость?<unk> ввостя<unk>иею. хамили, яма<unk>я пока<unk>ак <unk>ассии<unk>овать весь думал, что я станавенной п<unk>ега<unk>муки?<unk> а опередать платьи... г<unk>ускает про дело мантения себя есть, не пропулейно<unk><unk> я<unk>ий, на меня тех, чтобы выхбить.<unk> это не видится <unk> <unk>оде первый. а то. за него подлюбить!<unk> что вы вы<unk>е. я о этого ли<unk>ом, сделал <unk>е<unk>аны, и ему все празды мене со<unk><unk>одо<unk>уй заставьте ознав. и вы сесбее, тые...<unk> хорошо, лучше такое<unk>нибудь тотвовать с <unk>ости!<unk>.<unk> чупай... нат',\n",
       " '<bos>заходит улитка в ба<unk> отконтикома приходит! когда сейчас с всех хох <unk>аид голову мужывают и не хозадь. я покусию дает<unk> будовстан это на пичетесь домкой хотроковать ск не теща в ба<unk>у я <unk> во<unk>ди!лату!<unk> да может в жизню некидов <unk>отка она уп<unk>аненьку, уже у деряваться было има уже лет из койы учали<unk> <unk>гукую...<unk> на ее с тах. бы<unk><unk> нет.через все неработаской вечерска к это англиколонской!гить п<unk>абеся женщины <unk> водка по коновкомая на<unk>ужение в пенёнутневенега можешь так в усмопст матадот <unk>анка... это буду!<unk> кто очень нее только по <unk>ибании!<unk> так вам, все<unk>шую а<unk>мали... мне <unk>лые получился <unk>пимовка! муж иметь не хой!<unk> чтобы делаешь о себе алистельа, коби<unk>ают ев<unk>ысд хотитею...<unk> хорошо, в моем.пстянные то с две <unk>лополаса моател тства остр<unk>ют. а о на<unk>у<unk>. мне мужчинае гнучном пу<unk>их всейте в <unk>елич',\n",
       " '<bos>заходит улитка в ба<unk> войнечик... что жило диспоме<unk> сильное <unk> п<unk>тыкоты могуют, он ты воп<unk>етенини, когда в эта<unk>ите подуманенный головой двуманная недаствать так новиваются подавилась, чтобы <unk>мет...<unk> а вы вижу, чтобы со<unk>али!<unk> к вас, я у веров.?спил изусисвела мядуной ещу ногятся воп<unk>о<unk>ные, если так оспита? сойкам!<unk> я больше готов? но воло?<unk> никто на под<unk>итовкы сои<unk>ка<unk> по<unk>они... три все<unk>ночный мотвоую?<unk> а<unk>ак мужику?<unk> почему аканта не ле<unk>ате.<unk> даны и влела наклюлась. а не умешь зна<unk>о, п<unk>еви<unk>иейте! много никто носу работу. только у молчита дйта. это же вы <unk>купив ее безпеганулась<unk> и купата?<unk> приланва, колее<unk>ти<unk>е два в ко<unk>а<unk>ки?<unk> а она не проду твои четы<unk>а!<unk> это будет сойду. писле по<unk>чем<unk>есстре...<unk> изстать?<unk> какой мама можно анокопает! сметишь? вал<unk>ион<unk><unk>.. сдаве му<unk>ии. много ',\n",
       " '<bos>заходит улитка в ба<unk> лоданут г<unk>оечем совсем прокикчтоите пейск нововатия <unk>вета<unk> у меня не понимаю, но смотрит <unk> женщина не выпяли жизнь б<unk>аду на до немени<unk>. настои<unk>имельно<unk><unk> летной семесо наг<unk>ая <unk>еского васи сработво.ие закудати<unk>ов женщиненой? под<unk>елье прокуличионы в алкск<unk>... но такая нет... ввя<unk>и<unk> <unk>собачка. хгу <unk>адный <unk> видили <unk>ста<unk>ник <unk><unk> лету<unk> нача<unk>о!<unk> нахотый, его первая удова два п<unk>аех елье. как поживы работе аску не поставить... а можно, что ты чили тиизожилем. в этом такиих вачя неа у удали<unk><unk> а поверят <unk> теперь не отлчала для <unk>есть лет у<unk>жу...<unk> они сказали не платика?чинтво зат<unk>аются принца можно тека есть богатуй, п<unk>едпиика и приигатом ченд поченые оказающий <unk>валу.<unk> мужики после кото<unk>ым, устаскну<unk>!!то что вы своего....... а лювний попали<unk><unk> папа сделает тоть? да! олу<unk><unk>е...<unk> конечно хорошей приял',\n",
       " '<bos>заходит улитка в ба<unk> выдить в ки<unk>тун д<unk>опате<unk>она слу<unk>але лете перед на<unk>ать мать о таки мне в этом дие<unk>очке<unk>.<unk> да хоть сказала, плю<unk>, ты, я безоникае к<unk>асника продирать отец мне?<unk> мне с<unk>!мы бабочнее.<unk> дорогая <unk>имдоччет...похлев маленький принегальной отлица... очень прин яла встранился пока<unk>али и запасать <unk> заклибость <unk>удилики?капи<unk>ко<unk>ха с ску<unk>а говорят, что меня нужну своим президента.ни авда дать месли иды сегодня увестойтеспроних гостиваясти при сутит.<unk> кга<unk>но,. нагватеть сисуютесь, своим перв<unk>а! то междугокон вообще волство. и я что выдунеките за у тебя иг<unk>аними, следу первая она плохое. привы<unk>ив сделать в <unk>матоне, чугера микочка. будете?<unk> х<unk><unk>еств треной. таки мне мужик же помойски, как осладал?<unk> чем почу. им что у меня мцал, в майгоивд усозаи <unk>таной.!<unk>у у вас<unk><unk> не ошло? вот ведь больше тимооный.<unk>',\n",
       " '<bos>заходит улитка в ба<unk> не россии из а<unk>сутмен<unk>ерни у<unk>ыпе раз пасте, суливаться, натулуется дой еем <unk>удю, чтобы пивите у<unk>остно уже ли и ведь раза<unk>ается что больше.<unk>авливый, будетя...<unk> я такой не сою<unk>о не тоже мне кахза! я немхорошую мог! а а кто тебе <unk>ить отноца, а яма это силу?<unk>,?<unk> а под чем просто но<unk>евогителко, а без тебя?<unk> дунульно,, семы, двадет, и <unk>иг, сглазать <unk> во белобаме конги?<unk> ивлек!<unk> огле<unk>ют!.... я отноголька на па<unk>аешься бы боется мне <unk>зак на, этот плавать компали нап<unk>ав<unk>ешься натакеут носу!.. я <unk>кообитатано. куда.<unk> прида... цантности<unk>т к нам навнину, какой ты вашбастую. это у га<unk>еется и спялы внеснял! в катаи. анимель качат и поледила слонлекке в пупаниенит. настое дома вашего мходите одандато, если лет. знают п<unk>авда на духоча, заспоимения во<unk>можно ув',\n",
       " '<bos>заходит улитка в ба<unk> она гаранлял, скасть ему, а учитесь треил?<unk> ничего сперед, мужик.<unk><unk><unk> <unk>ек<unk>ия!<unk>!<unk> нет, <unk>количнисо<unk> на моск<unk>ия.<unk> х<unk>ер мертри<unk>бают...<unk> сы<unk>ительного любят на мыс<unk>емонти ты п<unk>ашу на дегва<unk>ии вечером. ук<unk>аанители<unk>...<unk> теч<unk>а. моли<unk>у это с новый прожином деренол! нострого водите<unk>? бол, ск<unk>убать.б<unk>ав об чанкто<unk>ос <unk>мимы<unk>ы и себя все не <unk> оп<unk>едотеперь его летит знать.<unk> перелив. отвидетику. не не видел, что ты ему уже промолось, что у похупилево<unk>овых... тут ты мне на воль, что уже <unk>еконов. а говорить сказать аввидели мивета, по зей.., это нимал?<unk> будить к голову!<unk>.<unk> богает, ва<unk><unk>ичй ее сталла,?<unk> я вашей человеку на трасти не между хо<unk>дись. а нет считать будешь зачем года. а я у<unk>дквал? у меня такой такой?<unk> сись интелаю?<unk>, за <unk>асстехов, из<unk>товно нет.нет этим любили.<unk> а п']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.inference(\"заходит улитка в бар \", device=device) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2. 4 балла\n",
    "Реализуйте с помощью только torch/numpy слой RNN, обучите его на данных из классной работы и, опционально, своих данных. Покажите, что модель обучается. \n",
    "\n",
    "### {*} Задача 2.1 +1 балл\n",
    "За реализацию слоев GRU/LSTM/bidirectional RNN, многослойной модели по +1 баллу к базовым за каждый слой (даже если ванильная RNN не реализована)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class SimpleRNNLayer:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Инициализация весов\n",
    "        self.Wx = torch.tensor(np.random.randn(input_size, hidden_size) * 0.01, dtype=torch.float32, requires_grad=True)\n",
    "        self.Wh = torch.tensor(np.random.randn(hidden_size, hidden_size) * 0.01, dtype=torch.float32, requires_grad=True)\n",
    "        self.Wy = torch.tensor(np.random.randn(hidden_size, output_size) * 0.01, dtype=torch.float32, requires_grad=True)\n",
    "        \n",
    "        self.bh = torch.zeros((1, hidden_size), dtype=torch.float32, requires_grad=True)\n",
    "        self.by = torch.zeros((1, output_size), dtype=torch.float32, requires_grad=True)\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        # Прямой проход\n",
    "        h_next = torch.tanh(x @ self.Wx + h_prev @ self.Wh + self.bh)\n",
    "        y = h_next @ self.Wy + self.by\n",
    "        return y, h_next\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Инициализация скрытого состояния\n",
    "        return torch.zeros((batch_size, self.hidden_size), dtype=torch.float32)\n",
    "        \n",
    "    def inference(self, input_seq, max_length=100):\n",
    "        # Преобразуем входную последовательность в тензор\n",
    "        if isinstance(input_seq, torch.Tensor):\n",
    "            x = input_seq\n",
    "        else:\n",
    "            x = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0)\n",
    "            \n",
    "        # Инициализируем скрытое состояние\n",
    "        h = self.init_hidden(1)\n",
    "        \n",
    "        outputs = []\n",
    "        \n",
    "        # Генерируем последовательность\n",
    "        for _ in range(max_length):\n",
    "            # Получаем предсказание\n",
    "            y, h = self.forward(x, h)\n",
    "            \n",
    "            # Применяем softmax для получения вероятностей\n",
    "            probs = torch.softmax(y, dim=-1)\n",
    "            \n",
    "            # Выбираем следующий токен\n",
    "            next_token = torch.multinomial(probs, 1)\n",
    "            \n",
    "            # Добавляем в выходную последовательность\n",
    "            outputs.append(next_token.item())\n",
    "            \n",
    "            # Подготавливаем вход для следующего шага\n",
    "            x = torch.zeros_like(input_seq)\n",
    "            x[0, next_token.item()] = 1\n",
    "            \n",
    "        return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "seq_length = 10\n",
    "input_size = 5\n",
    "hidden_size = 20\n",
    "output_size = 3\n",
    "\n",
    "# Инициализация модели\n",
    "rnn_layer = SimpleRNNLayer(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD([rnn_layer.Wx, rnn_layer.Wh, rnn_layer.Wy, rnn_layer.bh, rnn_layer.by], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (320) must match the size of tensor b (8) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Прямой проход\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m outputs, h \u001b[38;5;241m=\u001b[39m \u001b[43mrnn_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_prev\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# изменено: приведение входных данных к правильному размеру\u001b[39;00m\n\u001b[0;32m     14\u001b[0m h_prev \u001b[38;5;241m=\u001b[39m h  \u001b[38;5;66;03m# сохраняем состояние h для следующей итерации\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Вычисление потерь\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[63], line 21\u001b[0m, in \u001b[0;36mSimpleRNNLayer.forward\u001b[1;34m(self, x, h_prev)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, h_prev):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Прямой проход\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     h_next \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mh_prev\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWh\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbh)\n\u001b[0;32m     22\u001b[0m     y \u001b[38;5;241m=\u001b[39m h_next \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWy \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mby\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y, h_next\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (320) must match the size of tensor b (8) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "losses = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam([rnn_layer.Wx, rnn_layer.Wh, rnn_layer.Wy, rnn_layer.bh, rnn_layer.by], lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Прямой проход\n",
    "        outputs, h = rnn_layer.forward(inputs.view(-1, input_size), h_prev)  # изменено: приведение входных данных к правильному размеру\n",
    "        h_prev = h  # сохраняем состояние h для следующей итерации\n",
    "        \n",
    "        # Вычисление потерь\n",
    "        loss = criterion(outputs.view(-1, output_size), labels.view(-1))\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Обратный проход\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_loss /= len(dataloader)\n",
    "    losses.append(epoch_loss)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[rnn_layer.inference(\"заходит улитка в бар \", device=device) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "апиыв"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример датасета\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Пример данных\n",
    "num_samples = 1000\n",
    "seq_length = 10\n",
    "input_size = 5\n",
    "hidden_size = 20\n",
    "output_size = 3\n",
    "\n",
    "data = torch.randn(num_samples, seq_length, input_size)\n",
    "labels = torch.randint(0, output_size, (num_samples,))\n",
    "\n",
    "dataset = SequenceDataset(data, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Инициализация модели\n",
    "rnn_layer = SimpleRNNLayer(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD([rnn_layer.Wx, rnn_layer.Wh, rnn_layer.Wy, rnn_layer.bh, rnn_layer.by], lr=0.01)\n",
    "\n",
    "# Цикл обучения\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_data, batch_labels in dataloader:\n",
    "        batch_size = batch_data.size(0)\n",
    "        h_prev = rnn_layer.init_hidden(batch_size)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Прямой проход\n",
    "        for t in range(seq_length):\n",
    "            y_pred, h_prev = rnn_layer.forward(batch_data[:, t, :], h_prev)\n",
    "        \n",
    "        # Вычисление потерь\n",
    "        loss = criterion(y_pred, batch_labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Обратный проход и оптимизация\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0, 2, 0, 1, 2, 2, 2, 1, 1, 2, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq = torch.zeros(1, input_size)  # one-hot encoded начальный токен\n",
    "input_seq[0, 2] = 1\n",
    "rnn_layer.inference(input_seq, max_length=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 1 but got size 32 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 125\u001b[0m\n\u001b[0;32m    122\u001b[0m optimizer_lstm\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Прямой проход\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlstm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Вычисление потерь\u001b[39;00m\n\u001b[0;32m    128\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_labels)\n",
      "Cell \u001b[1;32mIn[48], line 24\u001b[0m, in \u001b[0;36mLSTMClassifier.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m     23\u001b[0m     x_t \u001b[38;5;241m=\u001b[39m x[:, t, :]\n\u001b[1;32m---> 24\u001b[0m     combined \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     f_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(torch\u001b[38;5;241m.\u001b[39mmatmul(combined, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWf\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf)\n\u001b[0;32m     27\u001b[0m     i_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(torch\u001b[38;5;241m.\u001b[39mmatmul(combined, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWi\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbi)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 1 but got size 32 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class LSTMClassifier:\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.Wf = torch.randn(hidden_size, input_size + hidden_size)  # Веса для забывающего ворота\n",
    "        self.Wi = torch.randn(hidden_size, input_size + hidden_size)  # Веса для входного ворота\n",
    "        self.Wc = torch.randn(hidden_size, input_size + hidden_size)  # Веса для ячейки\n",
    "        self.Wo = torch.randn(hidden_size, input_size + hidden_size)  # Веса для выходного ворота\n",
    "        self.bf = torch.zeros(hidden_size)  # Смещения для забывающего ворота\n",
    "        self.bi = torch.zeros(hidden_size)  # Смещения для входного ворота\n",
    "        self.bc = torch.zeros(hidden_size)  # Смещения для ячейки\n",
    "        self.bo = torch.zeros(hidden_size)  # Смещения для выходного ворота\n",
    "        self.fc = torch.randn(num_classes, hidden_size)  # Веса для полносвязного слоя\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_t = torch.zeros(self.hidden_size)\n",
    "        c_t = torch.zeros(self.hidden_size)\n",
    "        for t in range(x.size(1)):\n",
    "            x_t = x[:, t, :]\n",
    "            combined = torch.cat((h_t.unsqueeze(0).to(x.device), x_t), dim=1)\n",
    "\n",
    "            f_t = torch.sigmoid(torch.matmul(combined, self.Wf.T) + self.bf)\n",
    "            i_t = torch.sigmoid(torch.matmul(combined, self.Wi.T) + self.bi)\n",
    "            c_hat_t = torch.tanh(torch.matmul(combined, self.Wc.T) + self.bc)\n",
    "            c_t = f_t * c_t + i_t * c_hat_t\n",
    "            o_t = torch.sigmoid(torch.matmul(combined, self.Wo.T) + self.bo)\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "\n",
    "        out = torch.matmul(h_t, self.fc.T)  # Используем последний выход LSTM\n",
    "        return out\n",
    "\n",
    "class BiDirectionalRNNClassifier:\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.Wf = torch.randn(hidden_size, input_size + hidden_size)  # Веса для забывающего ворота\n",
    "        self.Wi = torch.randn(hidden_size, input_size + hidden_size)  # Веса для входного ворота\n",
    "        self.Wc = torch.randn(hidden_size, input_size + hidden_size)  # Веса для ячейки\n",
    "        self.Wo = torch.randn(hidden_size, input_size + hidden_size)  # Веса для выходного ворота\n",
    "        self.bf = torch.zeros(hidden_size)  # Смещения для забывающего ворота\n",
    "        self.bi = torch.zeros(hidden_size)  # Смещения для входного ворота\n",
    "        self.bc = torch.zeros(hidden_size)  # Смещения для ячейки\n",
    "        self.bo = torch.zeros(hidden_size)  # Смещения для выходного ворота\n",
    "        self.fc = torch.randn(num_classes, hidden_size)  # Веса для полносвязного слоя\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_t = torch.zeros(self.hidden_size)\n",
    "        c_t = torch.zeros(self.hidden_size)\n",
    "        seq_len = x.size(1)\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]\n",
    "            combined = torch.cat((h_t, x_t), dim=1)\n",
    "\n",
    "            f_t = torch.sigmoid(torch.matmul(combined, self.Wf.T) + self.bf)\n",
    "            i_t = torch.sigmoid(torch.matmul(combined, self.Wi.T) + self.bi)\n",
    "            c_hat_t = torch.tanh(torch.matmul(combined, self.Wc.T) + self.bc)\n",
    "            c_t = f_t * c_t + i_t * c_hat_t\n",
    "            o_t = torch.sigmoid(torch.matmul(combined, self.Wo.T) + self.bo)\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "\n",
    "        out = torch.matmul(h_t, self.fc.T)  # Используем последний выход\n",
    "        return out\n",
    "\n",
    "class GRUClassifier:\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.Wz = np.random.randn(hidden_size, input_size + hidden_size)  # Веса для обновляющего ворота\n",
    "        self.Wr = np.random.randn(hidden_size, input_size + hidden_size)  # Веса для сбрасывающего ворота\n",
    "        self.Wh = np.random.randn(hidden_size, input_size + hidden_size)  # Веса для ячейки\n",
    "        self.bz = np.zeros(hidden_size)  # Смещения для обновляющего ворота\n",
    "        self.br = np.zeros(hidden_size)  # Смещения для сбрасывающего ворота\n",
    "        self.bh = np.zeros(hidden_size)  # Смещения для ячейки\n",
    "        self.fc = np.random.randn(num_classes, hidden_size)  # Веса для полносвязного слоя\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_t = np.zeros((x.shape[0], self.hidden_size))\n",
    "        seq_len = x.shape[1]\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]\n",
    "            combined = np.hstack((h_t, x_t))\n",
    "\n",
    "            z_t = 1 / (1 + np.exp(-(np.dot(combined, self.Wz.T) + self.bz)))  # Обновляющее ворота\n",
    "            r_t = 1 / (1 + np.exp(-(np.dot(combined, self.Wr.T) + self.br)))  # Сбрасывающее ворота\n",
    "            h_hat_t = np.tanh(np.dot(np.hstack((r_t * h_t, x_t)), self.Wh.T) + self.bh)  # Ячейка\n",
    "            h_t = (1 - z_t) * h_t + z_t * h_hat_t  # Обновление состояния\n",
    "\n",
    "        out = np.dot(h_t, self.fc.T)  # Используем последний выход\n",
    "        return out\n",
    "\n",
    "# Инициализация моделей\n",
    "lstm_model = LSTMClassifier(input_size, hidden_size, output_size)  # Убрано .to(device)\n",
    "bi_model = BiDirectionalRNNClassifier(input_size, hidden_size, output_size)  # Убрано .to(device)\n",
    "gru_model = GRUClassifier(input_size, hidden_size, output_size)  # Убрано .to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.voc2int['<pad>'])\n",
    "optimizer_lstm = torch.optim.Adam([torch.tensor(lstm_model.Wf, dtype=torch.float32), \n",
    "                                     torch.tensor(lstm_model.Wi, dtype=torch.float32), \n",
    "                                     torch.tensor(lstm_model.Wc, dtype=torch.float32), \n",
    "                                     torch.tensor(lstm_model.Wo, dtype=torch.float32)], lr=1e-2)  # Используем веса LSTM\n",
    "optimizer_bi = torch.optim.Adam([torch.tensor(bi_model.Wf, dtype=torch.float32), \n",
    "                                   torch.tensor(bi_model.Wi, dtype=torch.float32), \n",
    "                                   torch.tensor(bi_model.Wc, dtype=torch.float32), \n",
    "                                   torch.tensor(bi_model.Wo, dtype=torch.float32)], lr=1e-2)  # Используем веса Bidirectional RNN\n",
    "optimizer_gru = torch.optim.Adam([torch.tensor(gru_model.Wz, dtype=torch.float32), \n",
    "                                    torch.tensor(gru_model.Wr, dtype=torch.float32), \n",
    "                                    torch.tensor(gru_model.Wh, dtype=torch.float32)], lr=1e-2)  # Используем веса GRU\n",
    "\n",
    "# Цикл обучения для LSTM\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_data, batch_labels in dataloader:\n",
    "        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "        \n",
    "        optimizer_lstm.zero_grad()\n",
    "        \n",
    "        # Прямой проход\n",
    "        outputs = lstm_model.forward(batch_data)\n",
    "        \n",
    "        # Вычисление потерь\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Обратный проход и оптимизация\n",
    "        loss.backward()\n",
    "        optimizer_lstm.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs} (LSTM), Loss: {total_loss/len(dataloader):.4f}')\n",
    "\n",
    "# Цикл обучения для Bidirectional RNN\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_data, batch_labels in dataloader:\n",
    "        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "        \n",
    "        optimizer_bi.zero_grad()\n",
    "        \n",
    "        # Прямой проход\n",
    "        outputs = bi_model(batch_data)\n",
    "        \n",
    "        # Вычисление потерь\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Обратный проход и оптимизация\n",
    "        loss.backward()\n",
    "        optimizer_bi.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs} (Bidirectional RNN), Loss: {total_loss/len(dataloader):.4f}')\n",
    "\n",
    "# Цикл обучения для GRU\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_data, batch_labels in dataloader:\n",
    "        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "        \n",
    "        optimizer_gru.zero_grad()\n",
    "        \n",
    "        # Прямой проход\n",
    "        outputs = gru_model(batch_data)\n",
    "        \n",
    "        # Вычисление потерь\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Обратный проход и оптимизация\n",
    "        loss.backward()\n",
    "        optimizer_gru.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs} (GRU), Loss: {total_loss/len(dataloader):.4f}')\n",
    "\n",
    "# Генерация текста\n",
    "def generate_text(model, start_token, max_length=50):\n",
    "    model.eval()\n",
    "    generated = [start_token]\n",
    "    input_seq = torch.zeros(1, max_length, input_size).to(device)\n",
    "    input_seq[0, 0, tokenizer.voc2int[start_token]] = 1  # one-hot encoding начального токена\n",
    "\n",
    "    for i in range(1, max_length):\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq[:, :i, :])\n",
    "            next_token = torch.argmax(output[:, -1, :], dim=1).item()\n",
    "            generated.append(tokenizer.int2voc[next_token])\n",
    "            input_seq[0, i, :] = 0\n",
    "            input_seq[0, i, next_token] = 1  # one-hot encoding следующего токена\n",
    "\n",
    "    return ''.join(generated)\n",
    "\n",
    "# Пример генерации текста\n",
    "start_token = '<bos>'\n",
    "generated_sequence = generate_text(lstm_model, start_token)\n",
    "print(\"Сгенерированная последовательность:\", generated_sequence)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 3. 4/5/6/7 баллов\n",
    "**TBD**: \n",
    "Попробуйте обучить рекуррентную сеть задаче классификации. Вы можете воспользоваться сторонними библиотеками для вашей работы, \n",
    "но модель и основной код должны быть написаны на pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [117] at entry 0 and [54] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 58\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_data, batch_labels \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     59\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     60\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(batch_data)\n",
      "File \u001b[1;32md:\\AllProjects\\FaceDetector\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32md:\\AllProjects\\FaceDetector\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\AllProjects\\FaceDetector\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\AllProjects\\FaceDetector\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\AllProjects\\FaceDetector\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32md:\\AllProjects\\FaceDetector\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    270\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [117] at entry 0 and [54] at entry 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Пример датасета\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Пример данных\n",
    "num_samples = 1000\n",
    "seq_length = 10\n",
    "input_size = 5\n",
    "num_classes = 3\n",
    "\n",
    "#data = torch.randn(num_samples, seq_length, input_size)\n",
    "#labels = torch.randint(0, num_classes, (num_samples,))\n",
    "\n",
    "#dataset = SequenceDataset(data, labels)\n",
    "#dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dataset = JokesDataset(tokenizer, cut_text, 256)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Определение модели\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])  # Используем последнее скрытое состояние\n",
    "        return out\n",
    "\n",
    "# Инициализация модели, функции потерь и оптимизатора\n",
    "hidden_size = 20\n",
    "model = RNNClassifier(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Цикл обучения\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_data, batch_labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_data)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "# Пример предсказания\n",
    "with torch.no_grad():\n",
    "    sample_data = torch.randn(1, seq_length, input_size)\n",
    "    prediction = model(sample_data)\n",
    "    predicted_class = torch.argmax(prediction, dim=1)\n",
    "    print(f'Predicted class: {predicted_class.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  {*} Задача 4. [5/6/7/8] баллов\n",
    "[ссылка](https://www.kaggle.com/t/b2ef08dc3ddf44f981e2ad186c6c508d)\n",
    "\n",
    "Попробуйте обучить сверточную нейронную сеть задаче детекции людей на изображениях разного стиля. Вы можете воспользоваться сторонними библиотеками для вашей работы. Однако, за неисопользование полностью готовых скриптов обучения (как в классной работе) вы получите дополнительные2 балла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Определяем трансформации для изображений\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Изменяем размер изображений\n",
    "    transforms.ToTensor(),  # Преобразуем в тензор\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Нормализуем изображения\n",
    "])\n",
    "\n",
    "# Создаем собственный датасет\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(image_folder) if f.endswith(('jpg', 'jpeg', 'png'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_folder, self.image_files[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "# Путь к папке с изображениями\n",
    "image_folder = '../additional_materials/images_dataset/'\n",
    "\n",
    "# Создаем экземпляр датасета\n",
    "dataset = ImageDataset(image_folder, transform=transform)\n",
    "\n",
    "# Создаем DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Пример использования DataLoader\n",
    "for images in dataloader:\n",
    "    print(images.shape)  # (batch_size, 3, 128, 128)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRASH\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "class SimpleTokenizer:\n",
    "    def __init__(self, text, max_vocab_size=322500):\n",
    "        self.text = text\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.special_tokens = ['<pad>', '<bos>', '<eos>', '<unk>']\n",
    "        \n",
    "        # Создаем словарь частотности слов\n",
    "        self.word_counts = Counter(self.text.split())\n",
    "        \n",
    "        # Ограничиваем размер словаря\n",
    "        self.vocab = self.special_tokens + [word for word, _ in self.word_counts.most_common(max_vocab_size - len(self.special_tokens))]\n",
    "        \n",
    "        # Создаем отображения слов в индексы и обратно\n",
    "        self.word2idx = {word: idx for idx, word in enumerate(self.vocab)}\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "\n",
    "        # Добавляем специальные токены\n",
    "        self._add_special(\"<pad>\")\n",
    "        self._add_special(\"<bos>\")\n",
    "        self._add_special(\"<eos>\")\n",
    "        self._add_special(\"<unk>\") # неизвестеые слова (не были включены в словарь токенайзера)\n",
    "\n",
    "    def _add_special(self, symbol):\n",
    "        idx = len(self.idx2word)\n",
    "        self.idx2word[idx] = symbol\n",
    "        self.word2idx[symbol] = idx\n",
    "\n",
    "    #@property\n",
    "    def encode(self, sentence):\n",
    "        # Преобразуем предложение в список индексов\n",
    "        words = sentence.split()\n",
    "        indices = [self.word2idx.get(word, self.word2idx['<unk>']) for word in words]\n",
    "        return [self.word2idx['<bos>']] + indices + [self.word2idx['<eos>']]\n",
    "\n",
    "    def decode(self, indices):\n",
    "        # Преобразуем список индексов обратно в предложение\n",
    "        words = [self.idx2word.get(idx, '<unk>') for idx in indices]\n",
    "        return ' '.join(words).replace('<bos> ', '').replace(' <eos>', '')\n",
    "\n",
    "    def pad_sequence(self, sequence, max_length):\n",
    "        # Дополняем последовательность до максимальной длины\n",
    "        if len(sequence) < max_length:\n",
    "            sequence += [self.word2idx['<pad>']] * (max_length - len(sequence))\n",
    "        return sequence[:max_length]\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "tokenizer = SimpleTokenizer(text)\n",
    "\n",
    "encoded = tokenizer.encode(\"Это пример текста для токенизации. Это еще один пример.\")\n",
    "print(\"Encoded:\", encoded)\n",
    "\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(\"Decoded:\", decoded)\n",
    "\n",
    "# Пример дополнения последовательности\n",
    "padded_sequence = tokenizer.pad_sequence(encoded, 20)\n",
    "print(\"Padded:\", padded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
