{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Iterable, Tuple\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|startoftext|>Друзья мои, чтобы соответствовать вам, я готов сделать над собой усилие и стать лучше. Но тогда и вы станьте немного хуже!\\n\\n<|startoftext|>- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н...\\n\\n<|startoftext|>- А вот скажи честно, ты во сне храпишь?- Понятие не имею, вроде, нет. От со'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r\"../../additional_materials/anek_djvu.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "text[118:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_data(text):\n",
    "    return text.replace(\"\\n\\n\", \"\").split(\"<|startoftext|>\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_text = cut_data(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Друзья мои, чтобы соответствовать вам, я готов сделать над собой усилие и стать лучше. Но тогда и вы станьте немного хуже!',\n",
       " '- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н...',\n",
       " '- А вот скажи честно, ты во сне храпишь?- Понятие не имею, вроде, нет. От собственного храпа по крайней мере еще ни разу не просыпался.- Ну, так у жены спроси.- А жена и подавно не знает. У нее странная привычка после замужества возникла: как спать ложится - беруши вставляет.',\n",
       " 'Поссорилась с мужем. Пока он спал, я мысленно развелась с ним, поделила имущество, переехала, поняла, что жить без него не могу, дала последний шанс, вернулась. В итоге, ложусь спать уже счастливой женщиной.',\n",
       " 'Если тебя посещают мысли о смерти - это еще полбеды. Беда - это когда смерть посещают мысли о тебе...']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_text[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1\n",
    "\n",
    "Обучите RNN/LSTM на данных из классной работы, используя другой токенайзер. Опишите его и свой выбор. Покажите разницу в генерации моделей, обученных с разными токенайзерами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенайзер из библиотеки **sentencepiece**: \n",
    "- работает с неразмеченными данными\n",
    "- разбивает его на подсловные юниты, что позволяет лучше справляться с редкими словами и морфологически сложными языками\n",
    "- поддерживает несколько методов токенизации, включая BPE (Byte Pair Encoding)\n",
    "\n",
    "BPE:\n",
    "- На каждом шаге алгоритм находит наиболее часто встречающуюся пару соседних символов или последовательностей символов и объединяет их в новый символ или токен.\n",
    "- Обновление: Этот процесс повторяется, пока не будет достигнуто заданное количество токенов или не останется частых пар для объединения.\n",
    "\n",
    "Преимущества:\n",
    "- Обработка редких слов: BPE позволяет разбивать редкие слова на более частые подсловные юниты, что улучшает обобщающую способность моделей.\n",
    "- Гибкость: Позволяет контролировать размер словаря, что важно для управления ресурсами и производительностью моделей.\n",
    "- Языконезависимость: Может применяться к любому языку, так как не зависит от предварительной сегментации на слова.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['▁', '|', 'startoftext', '|>', 'Д', 'ру', 'з', 'ь', 'я', '▁мо', 'и', ',', '▁чтобы', '▁со', 'о', 'т', 'вет', 'ство', 'вать', '▁ва', 'м', ',', '▁я', '▁го', 'то', 'в', '▁с', 'де', 'ла', 'ть', '▁на', 'д', '▁со', 'бо', 'й', '▁у', 'си', 'ли', 'е', '▁и', '▁ста', 'ть', '▁', 'лу', 'ч', 'ше', '.', '▁Н', 'о', '▁то', 'гда', '▁и', '▁вы', '▁ста', 'нь', 'те', '▁не', 'м', 'ного', '▁х', 'уж', 'е', '!', '▁<|', 'startoftext', '|>-', '▁', 'Л', 'ю', 'ся', ',', '▁ты', '▁все', '▁еще', '▁х', 'ра', 'ни', 'шь', '▁мо', 'й', '▁по', 'да', 'ро', 'к', '?-', '▁Да', '.-', '▁Я', '▁ду', 'ма', 'л', ',', '▁ты', '▁вы', 'ки', 'ну', 'ла', '▁все', ',', '▁что', '▁со', '▁м', 'ной', '▁с', 'в', 'я', 'за', 'но', '.-', '▁П', 'лю', 'ше', 'вы', 'й', '▁ми', 'шка', '▁не', '▁ви', 'но', 'ва', 'т', ',', '▁что', '▁ты', '▁е', 'б', 'л', '@', 'н', '...', '▁<|', 'startoftext', '|>-', '▁А', '▁во', 'т', '▁с', 'ка', 'жи', '▁че', 'ст', 'но', ',', '▁ты', '▁во', '▁с', 'не', '▁х', 'ра', 'пи', 'шь', '?-', '▁По', 'ня', 'ти', 'е', '▁не', '▁и', 'ме', 'ю', ',', '▁в', 'ро', 'де', ',', '▁нет', '.', '▁О', 'т', '▁со']\n",
      "Detokenized text: |startoftext|>Друзья мои, чтобы соответствовать вам, я готов сделать над собой усилие и стать лучше. Но тогда и вы станьте немного хуже! <|startoftext|>- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н... <|startoftext|>- А вот скажи честно, ты во сне храпишь?- Понятие не имею, вроде, нет. От со\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../../additional_materials/anek_djvu.txt\n",
      "  input_format: \n",
      "  model_prefix: m\n",
      "  model_type: BPE\n",
      "  vocab_size: 454\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: ../../additional_materials/anek_djvu.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 124166 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=15747197\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 99.9516% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=92\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.999516\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 124166 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 124166\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 322153\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=185805 min_freq=98\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=100295 size=20 all=2633 active=1303 piece=ет\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=61513 size=40 all=3822 active=2492 piece=▁не\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35781 size=60 all=5409 active=4079 piece=ны\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23902 size=80 all=6687 active=5357 piece=ди\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20456 size=100 all=8334 active=7004 piece=ве\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=20338 min_freq=1472\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17428 size=120 all=10012 active=2545 piece=ени\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14911 size=140 all=11964 active=4497 piece=по\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12286 size=160 all=13519 active=6052 piece=ву\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10571 size=180 all=15414 active=7947 piece=кой\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9111 size=200 all=17274 active=9807 piece=сти\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8911 min_freq=1249\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7813 size=220 all=19000 active=2571 piece=лы\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6986 size=240 all=20110 active=3681 piece=▁ста\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6422 size=260 all=21971 active=5542 piece=дь\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5806 size=280 all=23539 active=7110 piece=▁ми\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5067 size=300 all=24813 active=8384 piece=ения\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5055 min_freq=885\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4641 size=320 all=25910 active=2304 piece=кто\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4243 size=340 all=27284 active=3678 piece=▁нет\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: m.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: m.vocab\n"
     ]
    }
   ],
   "source": [
    "   import sentencepiece as spm\n",
    "\n",
    "   with open(r\"../../additional_materials/anek_djvu.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "       text = f.read()\n",
    "\n",
    "   # Обучаем токенайзер\n",
    "   spm.SentencePieceTrainer.train(input='../../additional_materials/anek_djvu.txt', model_prefix='m', vocab_size=454, model_type='bpe')\n",
    "\n",
    "   # Загружаем обученный токенайзер\n",
    "   sp = spm.SentencePieceProcessor();\n",
    "   sp.load('m.model') # загружаем модель в файл\n",
    "\n",
    "   # Токенизация текста\n",
    "   tokens = sp.encode_as_pieces(text[118:500])\n",
    "   print(\"Tokens:\", tokens)\n",
    "\n",
    "   # Детокенизация\n",
    "   detokenized_text = sp.decode_pieces(tokens)\n",
    "   print(\"Detokenized text:\", detokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPTokenizer:\n",
    "    def __init__(self, model_path: str):\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.load(model_path)\n",
    "    \n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return self.sp.get_piece_size()\n",
    "        \n",
    "    def encode(self, text):\n",
    "        return self.sp.encode_as_ids(text)\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        return self.sp.decode_ids(ids)\n",
    "    \n",
    "    def encode_symbol(self, symbol):\n",
    "        return self.sp.piece_to_id(symbol)\n",
    "    \n",
    "    def decode_symbol(self, id):\n",
    "        return self.sp.id_to_piece(id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded text: [95, 52, 306, 383, 154, 143, 44, 404]\n",
      "Decoded text: Привет, как дела?\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SPTokenizer('m.model')\n",
    "\n",
    "# Пример использования\n",
    "text = \"Привет, как дела?\"\n",
    "encoded_text = tokenizer.encode(text)\n",
    "print(\"Encoded text:\", encoded_text)\n",
    "\n",
    "decoded_text = tokenizer.decode(encoded_text)\n",
    "print(\"Decoded text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokesDataset(Dataset):\n",
    "    def __init__(self, tokenizer, cut_text, max_len: int = 512):\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cut_text = cut_text\n",
    "        self.pad_index = self.tokenizer.encode_symbol(\"<pad>\")\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        # pad your sequence and make a final sample. You can skip padding and pad sequences with torch special method.\n",
    "        #text = self.cut_text[item]\n",
    "        encoded = self.tokenizer.encode(text)  # Токенизируем строку\n",
    "\n",
    "        if len(encoded) > self.max_len:\n",
    "            encoded = encoded[:self.max_len]\n",
    "\n",
    "        # Создаем тензор padded с размером max_len\n",
    "        padded = torch.full((self.max_len, ), self.pad_index, dtype=torch.long)\n",
    "        # Заполняем тензор padded значениями из encoded\n",
    "        padded[:len(encoded)] = torch.tensor(encoded)\n",
    "\n",
    "        return padded, len(encoded)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.cut_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, tokenizer, embedding_dim=128, hidden_dim=256, num_layers=2, drop_prob=0.5):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab_size = tokenizer.vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(self.vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        # Полносвязный слой\n",
    "        self.fc = nn.Linear(hidden_dim, self.vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # Пропускаем входные данные через слой эмбеддингов\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Пропускаем через LSTM\n",
    "        lstm_out, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        # Применяем dropout\n",
    "        out = self.dropout(lstm_out)\n",
    "        \n",
    "        # Пропускаем через полносвязный слой\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # Возвращаем выход и скрытое состояние\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size, device):\n",
    "        # Инициализируем скрытое состояние нулями\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new_zeros(self.num_layers, batch_size, self.hidden_dim).to(device),\n",
    "                  weight.new_zeros(self.num_layers, batch_size, self.hidden_dim).to(device))\n",
    "        return hidden\n",
    "\n",
    "    def inference(self, start_text, device, max_length=100):\n",
    "        self.eval()  # Переключаем модель в режим оценки\n",
    "        tokens = self.tokenizer.encode(start_text)\n",
    "        tokens_tensor = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "        hidden = self.init_hidden(1, device)\n",
    "\n",
    "        generated_text = start_text\n",
    "\n",
    "        for _ in range(max_length):\n",
    "            output, hidden = self.forward(tokens_tensor, hidden)\n",
    "            probabilities = torch.softmax(output[:, -1], dim=-1)\n",
    "            next_token = torch.argmax(probabilities, dim=-1).item()\n",
    "            tokens_tensor = torch.cat((tokens_tensor, torch.tensor([[next_token]]).to(device)), dim=1)\n",
    "\n",
    "            if next_token == self.tokenizer.encode_symbol(\"<eos>\"):\n",
    "                break\n",
    "\n",
    "            generated_text += self.tokenizer.decode([next_token])\n",
    "\n",
    "        return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим параметры для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "seq_length = 128\n",
    "n_hidden = 64\n",
    "n_layers = 2\n",
    "drop_prob = 0.1\n",
    "lr = 0.1\n",
    "embedding_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(\n",
    "    model: LSTM,\n",
    "    train_batch: Tuple[torch.Tensor, torch.Tensor],\n",
    "    vocab_size: int,\n",
    "    criterion: nn.Module,\n",
    "    optimizer,\n",
    "    device=\"cpu\"\n",
    ") -> torch.Tensor:\n",
    "    \n",
    "    batch_size, seq_len = train_batch[0].shape\n",
    "    \n",
    "    # Переводим данные на устройство\n",
    "    inputs = train_batch[0].to(device)\n",
    "    targets = train_batch[0].to(device)  # Изменено: используем inputs для targets\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Прямой проход\n",
    "    output = model(inputs, torch.tensor([seq_len] * batch_size).to(device))\n",
    "    \n",
    "    # Изменено: Преобразуем выходные данные в нужную форму\n",
    "    logits = output.view(-1, vocab_size)\n",
    "    targets = targets.view(-1)\n",
    "    \n",
    "    # Вычисляем функцию потерь\n",
    "    loss = criterion(logits, targets)\n",
    "    \n",
    "    # Обратный проход и оптимизация\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Пример использования\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\nmodel = WordLSTM(tokenizer).to(device)\\n\\n# Инициализация скрытого состояния\\nbatch_size = 32\\nhidden = model.init_hidden(batch_size, device)\\n\\n# Пример входных данных\\ninput_data = torch.randint(0, tokenizer.vocab_size, (batch_size, 10)).to(device)\\n\\n# Прямой проход\\noutput, hidden = model(input_data, hidden)\\nprint(output.shape)  # Ожидаемый размер: (batch_size, sequence_length, vocab_size)\\n'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Пример использования\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = WordLSTM(tokenizer).to(device)\n",
    "\n",
    "# Инициализация скрытого состояния\n",
    "batch_size = 32\n",
    "hidden = model.init_hidden(batch_size, device)\n",
    "\n",
    "# Пример входных данных\n",
    "input_data = torch.randint(0, tokenizer.vocab_size, (batch_size, 10)).to(device)\n",
    "\n",
    "# Прямой проход\n",
    "output, hidden = model(input_data, hidden)\n",
    "print(output.shape)  # Ожидаемый размер: (batch_size, sequence_length, vocab_size)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = LSTM(tokenizer, embedding_dim, n_hidden, n_layers, drop_prob).to(device)\n",
    "hidden = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Улитка заходит в бар ветбебебебеновет<<<больбольннениеНаттНатротНаттНаfНаНароНаттНаfНаНароНаттНаfНаНароНаттНаfНаНароНаттНаfНаНароНаттНаfНаНароНаттНаfНаНароНаттНаfНаНароНаттНаfНаНароНаттНаfНа'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inference(\"Улитка заходит в бар \", device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses):\n",
    "    clear_output()\n",
    "    plt.plot(range(1, len(losses) + 1), losses)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dataset = JokesDataset(tokenizer, cut_text, 256)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "For batched 3-D input, hx and cx should also be 3-D but got (0-D, 0-D) tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[216], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m----> 7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[210], line 19\u001b[0m, in \u001b[0;36mtraining_step\u001b[0;34m(model, train_batch, vocab_size, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Прямой проход\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Изменено: Преобразуем выходные данные в нужную форму\u001b[39;00m\n\u001b[1;32m     22\u001b[0m logits \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, vocab_size)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[208], line 24\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     21\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Пропускаем через LSTM\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m lstm_out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Применяем dropout\u001b[39;00m\n\u001b[1;32m     27\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(lstm_out)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/rnn.py:904\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m    902\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor batched 3-D input, hx and cx should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    903\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malso be 3-D but got (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D) tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 904\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: For batched 3-D input, hx and cx should also be 3-D but got (0-D, 0-D) tensors"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        loss = training_step(model, batch, tokenizer.vocab_size, criterion, optimizer, device)\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f'Done {i/len(dataloader) * 100:.2f}%, Loss: {loss:.4f}')\n",
    "    epoch_loss /= len(dataloader)\n",
    "    losses.append(epoch_loss)\n",
    "    \n",
    "    plot_losses(losses)\n",
    "    torch.save(model.state_dict(), \"rnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "For batched 3-D input, hx and cx should also be 3-D but got (0-D, 0-D) tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[196], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hidden[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     13\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m (hidden[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), hidden[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m---> 14\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     16\u001b[0m counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[190], line 19\u001b[0m, in \u001b[0;36mtraining_step\u001b[0;34m(model, train_batch, vocab_size, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Прямой проход\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Изменено: Преобразуем выходные данные в нужную форму\u001b[39;00m\n\u001b[1;32m     22\u001b[0m logits \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, vocab_size)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[188], line 24\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     21\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Пропускаем через LSTM\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m lstm_out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Применяем dropout\u001b[39;00m\n\u001b[1;32m     27\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(lstm_out)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/rnn.py:904\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m    902\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor batched 3-D input, hx and cx should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    903\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malso be 3-D but got (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D) tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 904\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: For batched 3-D input, hx and cx should also be 3-D but got (0-D, 0-D) tensors"
     ]
    }
   ],
   "source": [
    "'''losses = []\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_loss = 0\n",
    "    hidden = model.init_hidden(batch_size, device)\n",
    "    \n",
    "    print(len(dataloader))\n",
    "    counter = 0\n",
    "    for batch in dataloader:\n",
    "        hidden = tuple([each.data for each in hidden])\n",
    "        if hidden[0].dim() == 2:\n",
    "            hidden = (hidden[0].unsqueeze(0), hidden[1].unsqueeze(0))\n",
    "        loss = training_step(model, batch, tokenizer.vocab_size, criterion, optimizer, device)\n",
    "        epoch_loss += loss\n",
    "        counter += 1\n",
    "        if counter % 100 == 0:\n",
    "            print(counter)\n",
    "        \n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    losses.append(avg_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch}, Loss: {avg_loss:.4f}')\n",
    "    plot_losses(losses)\n",
    "    torch.save(model.state_dict(), \"rnn.pt\")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[model.inference(\"Однажды \", device=device) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## {*} Задача 1.1 2 балла\n",
    "Напишите свой токенайзер вручную, с использованием только библиотек numpy, torch, sklearn, stats, опционально других пакетов, не предоставляющих готовые инструменты токенизации и т.п., за исключением предобработки текста (лемматизация, стеминг и т.д.) . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем токенайзер, который будет разбивать текст на слова и сохранять их в словарь, а также добавлять специальные токены для начала и конца предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordTokenizer:\n",
    "    def __init__(self, text, max_len=512):\n",
    "        self.text = text\n",
    "        self.max_len = max_len\n",
    "        self.specials = ['<pad>', '<bos>', '<eos>']\n",
    "        \n",
    "        # Создаем словарь уникальных слов\n",
    "        words = set(text.split())\n",
    "        self.int2word = {i: word for i, word in enumerate(words)}\n",
    "        self.word2int = {word: i for i, word in self.int2word.items()}\n",
    "        \n",
    "        # Добавляем специальные токены\n",
    "        self._add_special(\"<pad>\")\n",
    "        self._add_special(\"<bos>\")\n",
    "        self._add_special(\"<eos>\")\n",
    "\n",
    "    def _add_special(self, symbol):\n",
    "        idx = len(self.int2word)\n",
    "        self.int2word[idx] = symbol\n",
    "        self.word2int[symbol] = idx\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.int2word)\n",
    "\n",
    "    def encode(self, sentence):\n",
    "        words = ['<bos>'] + sentence.split() + ['<eos>']\n",
    "        return [self.word2int.get(word, self.word2int['<pad>']) for word in words]\n",
    "\n",
    "    def decode(self, indices):\n",
    "        words = [self.int2word.get(index, '<pad>') for index in indices]\n",
    "        return ' '.join(words).replace('<bos> ', '').replace(' <eos>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [322452, 268037, 43138, 52361, 267605, 322451, 268037, 164829, 321060, 52151, 322453]\n",
      "Decoded: Это пример текста для <pad> Это еще один пример.\n"
     ]
    }
   ],
   "source": [
    " with open(r\"../../additional_materials/anek_djvu.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "       text = f.read()\n",
    "\n",
    "# Пример использования\n",
    "tokenizer = WordTokenizer(text)\n",
    "\n",
    "encoded = tokenizer.encode(\"Это пример текста для токенизации. Это еще один пример.\")\n",
    "print(\"Encoded:\", encoded)\n",
    "\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(\"Decoded:\", decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2. 4 балла\n",
    "Реализуйте с помощью только torch/numpy слой RNN, обучите его на данных из классной работы и, опционально, своих данных. Покажите, что модель обучается. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.0986\n",
      "Epoch 2/10, Loss: 1.0985\n",
      "Epoch 3/10, Loss: 1.0983\n",
      "Epoch 4/10, Loss: 1.0982\n",
      "Epoch 5/10, Loss: 1.0984\n",
      "Epoch 6/10, Loss: 1.0982\n",
      "Epoch 7/10, Loss: 1.0980\n",
      "Epoch 8/10, Loss: 1.0976\n",
      "Epoch 9/10, Loss: 1.0978\n",
      "Epoch 10/10, Loss: 1.0975\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class SimpleRNNLayer:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Инициализация весов\n",
    "        self.Wx = torch.tensor(np.random.randn(input_size, hidden_size) * 0.01, dtype=torch.float32, requires_grad=True)\n",
    "        self.Wh = torch.tensor(np.random.randn(hidden_size, hidden_size) * 0.01, dtype=torch.float32, requires_grad=True)\n",
    "        self.Wy = torch.tensor(np.random.randn(hidden_size, output_size) * 0.01, dtype=torch.float32, requires_grad=True)\n",
    "        \n",
    "        self.bh = torch.zeros((1, hidden_size), dtype=torch.float32, requires_grad=True)\n",
    "        self.by = torch.zeros((1, output_size), dtype=torch.float32, requires_grad=True)\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        # Прямой проход\n",
    "        h_next = torch.tanh(x @ self.Wx + h_prev @ self.Wh + self.bh)\n",
    "        y = h_next @ self.Wy + self.by\n",
    "        return y, h_next\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Инициализация скрытого состояния\n",
    "        return torch.zeros((batch_size, self.hidden_size), dtype=torch.float32)\n",
    "\n",
    "# Пример датасета\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Пример данных\n",
    "num_samples = 1000\n",
    "seq_length = 10\n",
    "input_size = 5\n",
    "hidden_size = 20\n",
    "output_size = 3\n",
    "\n",
    "data = torch.randn(num_samples, seq_length, input_size)\n",
    "labels = torch.randint(0, output_size, (num_samples,))\n",
    "\n",
    "dataset = SequenceDataset(data, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Инициализация модели\n",
    "rnn_layer = SimpleRNNLayer(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD([rnn_layer.Wx, rnn_layer.Wh, rnn_layer.Wy, rnn_layer.bh, rnn_layer.by], lr=0.01)\n",
    "\n",
    "# Цикл обучения\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_data, batch_labels in dataloader:\n",
    "        batch_size = batch_data.size(0)\n",
    "        h_prev = rnn_layer.init_hidden(batch_size)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Прямой проход\n",
    "        for t in range(seq_length):\n",
    "            y_pred, h_prev = rnn_layer.forward(batch_data[:, t, :], h_prev)\n",
    "        \n",
    "        # Вычисление потерь\n",
    "        loss = criterion(y_pred, batch_labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Обратный проход и оптимизация\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 3. 4/5/6/7 баллов\n",
    "**TBD**: \n",
    "Попробуйте обучить рекуррентную сеть задаче классификации. Вы можете воспользоваться сторонними библиотеками для вашей работы, \n",
    "но модель и основной код должны быть написаны на pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "full() received an invalid combination of arguments - got (int, int, dtype=torch.dtype), but expected one of:\n * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[178], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 58\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[177], line 17\u001b[0m, in \u001b[0;36mJokesDataset.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     14\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m encoded[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_len]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Создаем тензор padded с размером max_len\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m padded \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Заполняем тензор padded значениями из encoded\u001b[39;00m\n\u001b[1;32m     19\u001b[0m padded[:\u001b[38;5;28mlen\u001b[39m(encoded)] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(encoded)\n",
      "\u001b[0;31mTypeError\u001b[0m: full() received an invalid combination of arguments - got (int, int, dtype=torch.dtype), but expected one of:\n * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Пример датасета\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Пример данных\n",
    "num_samples = 1000\n",
    "seq_length = 10\n",
    "input_size = 5\n",
    "num_classes = 3\n",
    "\n",
    "#data = torch.randn(num_samples, seq_length, input_size)\n",
    "#labels = torch.randint(0, num_classes, (num_samples,))\n",
    "\n",
    "#dataset = SequenceDataset(data, labels)\n",
    "#dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dataset = JokesDataset(tokenizer, cut_text, 256)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Определение модели\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])  # Используем последнее скрытое состояние\n",
    "        return out\n",
    "\n",
    "# Инициализация модели, функции потерь и оптимизатора\n",
    "hidden_size = 20\n",
    "model = RNNClassifier(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Цикл обучения\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_data, batch_labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_data)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "# Пример предсказания\n",
    "with torch.no_grad():\n",
    "    sample_data = torch.randn(1, seq_length, input_size)\n",
    "    prediction = model(sample_data)\n",
    "    predicted_class = torch.argmax(prediction, dim=1)\n",
    "    print(f'Predicted class: {predicted_class.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  {*} Задача 4. [5/6/7/8] баллов\n",
    "[ссылка](https://www.kaggle.com/t/b2ef08dc3ddf44f981e2ad186c6c508d)\n",
    "\n",
    "Попробуйте обучить сверточную нейронную сеть задаче детекции людей на изображениях разного стиля. Вы можете воспользоваться сторонними библиотеками для вашей работы. Однако, за неисопользование полностью готовых скриптов обучения (как в классной работе) вы получите дополнительные2 балла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Определяем трансформации для изображений\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Изменяем размер изображений\n",
    "    transforms.ToTensor(),  # Преобразуем в тензор\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Нормализуем изображения\n",
    "])\n",
    "\n",
    "# Создаем собственный датасет\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(image_folder) if f.endswith(('jpg', 'jpeg', 'png'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_folder, self.image_files[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "# Путь к папке с изображениями\n",
    "image_folder = '../additional_materials/images_dataset/'\n",
    "\n",
    "# Создаем экземпляр датасета\n",
    "dataset = ImageDataset(image_folder, transform=transform)\n",
    "\n",
    "# Создаем DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Пример использования DataLoader\n",
    "for images in dataloader:\n",
    "    print(images.shape)  # (batch_size, 3, 128, 128)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRASH\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "class SimpleTokenizer:\n",
    "    def __init__(self, text, max_vocab_size=322500):\n",
    "        self.text = text\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.special_tokens = ['<pad>', '<bos>', '<eos>', '<unk>']\n",
    "        \n",
    "        # Создаем словарь частотности слов\n",
    "        self.word_counts = Counter(self.text.split())\n",
    "        \n",
    "        # Ограничиваем размер словаря\n",
    "        self.vocab = self.special_tokens + [word for word, _ in self.word_counts.most_common(max_vocab_size - len(self.special_tokens))]\n",
    "        \n",
    "        # Создаем отображения слов в индексы и обратно\n",
    "        self.word2idx = {word: idx for idx, word in enumerate(self.vocab)}\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "\n",
    "        # Добавляем специальные токены\n",
    "        self._add_special(\"<pad>\")\n",
    "        self._add_special(\"<bos>\")\n",
    "        self._add_special(\"<eos>\")\n",
    "        self._add_special(\"<unk>\") # неизвестеые слова (не были включены в словарь токенайзера)\n",
    "\n",
    "    def _add_special(self, symbol):\n",
    "        idx = len(self.idx2word)\n",
    "        self.idx2word[idx] = symbol\n",
    "        self.word2idx[symbol] = idx\n",
    "\n",
    "    #@property\n",
    "    def encode(self, sentence):\n",
    "        # Преобразуем предложение в список индексов\n",
    "        words = sentence.split()\n",
    "        indices = [self.word2idx.get(word, self.word2idx['<unk>']) for word in words]\n",
    "        return [self.word2idx['<bos>']] + indices + [self.word2idx['<eos>']]\n",
    "\n",
    "    def decode(self, indices):\n",
    "        # Преобразуем список индексов обратно в предложение\n",
    "        words = [self.idx2word.get(idx, '<unk>') for idx in indices]\n",
    "        return ' '.join(words).replace('<bos> ', '').replace(' <eos>', '')\n",
    "\n",
    "    def pad_sequence(self, sequence, max_length):\n",
    "        # Дополняем последовательность до максимальной длины\n",
    "        if len(sequence) < max_length:\n",
    "            sequence += [self.word2idx['<pad>']] * (max_length - len(sequence))\n",
    "        return sequence[:max_length]\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "tokenizer = SimpleTokenizer(text)\n",
    "\n",
    "encoded = tokenizer.encode(\"Это пример текста для токенизации. Это еще один пример.\")\n",
    "print(\"Encoded:\", encoded)\n",
    "\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(\"Decoded:\", decoded)\n",
    "\n",
    "# Пример дополнения последовательности\n",
    "padded_sequence = tokenizer.pad_sequence(encoded, 20)\n",
    "print(\"Padded:\", padded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
